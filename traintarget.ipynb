{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.arrays import boolean\n",
    "import torch\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import models\n",
    "import utils as ut\n",
    "from models import AEBase, Predictor, PretrainedPredictor\n",
    "\n",
    "import scanpypip.preprocessing as pp\n",
    "import scanpypip.utils as scut \n",
    "\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):   \n",
    "        self.epochs = 500\n",
    "        self.bottleneck = 512\n",
    "        self.missing_value = np.nan\n",
    "        self.data_path = \"data/GSE108394/GSM2897334/\"\n",
    "        self.test_size = 0.2\n",
    "        self.valid_size = 0.2\n",
    "        self.model_store_path = \"saved/models/\"\n",
    "        self.logging_file = \"saved/logs/\"\n",
    "        self.batch_size = 200\n",
    "        self.ft_h_dims = \"512,256\"\n",
    "        self.var_genes_disp = 0\n",
    "        self.pretrain_path = \"saved/models/\"\n",
    "        self.min_n_genes = 0\n",
    "        self.max_n_genes = 20000\n",
    "        self.min_g = 200\n",
    "        self.min_c = 3\n",
    "\n",
    "        \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = args.epochs\n",
    "dim_au_out = args.bottleneck #8, 16, 32, 64, 128, 256,512\n",
    "dim_dnn_in = dim_au_out\n",
    "dim_dnn_out=1\n",
    "na = args.missing_value\n",
    "data_path = args.data_path\n",
    "test_size = args.test_size\n",
    "valid_size = args.valid_size\n",
    "g_disperson = args.var_genes_disp\n",
    "min_n_genes = args.min_n_genes\n",
    "max_n_genes = args.max_n_genes\n",
    "model_path = args.model_store_path\n",
    "pretrain_path = args.pretrain_path\n",
    "log_path = args.logging_file\n",
    "batch_size = args.batch_size\n",
    "encoder_hdims = args.ft_h_dims.split(\",\")\n",
    "encoder_hdims = list(map(int, encoder_hdims))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now=time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "log_path = log_path+now+\".txt\"\n",
    "export_name = data_path.replace(\"/\",\"\")\n",
    "pretrain_path = \"saved/models/ae_\"+export_name+now+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scv = pd.read_csv('data/GSE117872/GSE117872_good_Data_TPM.txt',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = pp.read_sc_file('data/GSE117872/GSE117872_good_Data_TPM.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = sc.read_10x_mtx(\n",
    "#  'data/GSE108394/GSM2897334/',  # the directory with the `.mtx` file \n",
    "#  var_names='gene_symbols',                # use gene symbols for the variable names (variables-axis index)\n",
    "#  cache=True)                              # write a cache file for faster subsequent reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata = sc.pp.filter_cells(adata, min_genes=200)\n",
    "#adata = sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "adata =pp.cal_ncount_ngenes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(adata, ['n_counts',\"percent_mito\",'percent_rps', 'percent_rpl'],\n",
    "             jitter=0.4, multi_panel=True,save=export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata = pp.receipe_my(adata,l_n_genes=min_n_genes,r_n_genes=max_n_genes,filter_mincells=args.min_c,\n",
    "                      filter_mingenes=args.min_g,normalize=True,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata,min_disp=g_disperson,max_disp=np.inf)\n",
    "\n",
    "sc.pl.highly_variable_genes(adata,save=export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw = adata\n",
    "\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "data=adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mmscaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(data, test_size=valid_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# Construct datasets and data loaders\n",
    "X_trainTensor = torch.FloatTensor(X_train).to(device)\n",
    "X_validTensor = torch.FloatTensor(X_valid).to(device)\n",
    "X_allTensor = torch.FloatTensor(data).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_trainTensor, X_trainTensor)\n",
    "valid_dataset = TensorDataset(X_validTensor, X_validTensor)\n",
    "all_dataset = TensorDataset(X_allTensor, X_allTensor)\n",
    "\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_pretrain = {'train':X_trainDataLoader,'val':X_validDataLoader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_trainDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AEBase(input_dim=data.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims)\n",
    "#model = VAE(dim_au_in=data_r.shape[1],dim_au_out=128)\n",
    "if torch.cuda.is_available():\n",
    "    encoder.cuda()\n",
    "\n",
    "print(encoder)\n",
    "encoder.to(device)\n",
    "optimizer_e = optim.Adam(encoder.parameters(), lr=1e-2)\n",
    "loss_function_e = nn.MSELoss()\n",
    "exp_lr_scheduler_e = lr_scheduler.ReduceLROnPlateau(optimizer_e)\n",
    "encoder,loss_report_en = ut.train_extractor_model(net=encoder,data_loaders=dataloaders_pretrain,\n",
    "                            optimizer=optimizer_e,loss_function=loss_function_e,\n",
    "                            n_epochs=epochs,scheduler=exp_lr_scheduler_e,save_path=pretrain_path)\n",
    "\n",
    "print(\"Pretrained finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.encode(X_allTensor).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"X_AE\"] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, n_neighbors=10,use_rep=\"X_AE\")\n",
    "#sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.tsne(adata,use_rep=\"X_AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.tsne(adata,save=export_name,color=[\"leiden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon')\n",
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False,save=export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"saved/results\"+export_name+\".h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
