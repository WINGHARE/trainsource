{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "#import scipy.io as sio\n",
    "\n",
    "from models import VAE,AEBase\n",
    "from models import DNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import models\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "epochs = 500 #200,500,1000  \n",
    "#dim_au_in = 20049\n",
    "dim_au_out = 512 #8, 16, 32, 64, 128, 256,512\n",
    "dim_dnn_in = dim_au_out\n",
    "dim_dnn_out=1\n",
    "select_drug = 'Gefitinib'\n",
    "na = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r=pd.read_csv('data/GDSCexpression.csv',index_col=0)\n",
    "label_r=pd.read_csv('data/GDSClabel.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_r=label_r.fillna(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "hvg,adata = ut.highly_variable_genes(data_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Erlotinib</th>\n",
       "      <th>AICAR</th>\n",
       "      <th>Camptothecin</th>\n",
       "      <th>Vinblastine</th>\n",
       "      <th>Cisplatin</th>\n",
       "      <th>Cytarabine</th>\n",
       "      <th>Docetaxel</th>\n",
       "      <th>Methotrexate</th>\n",
       "      <th>ATRA</th>\n",
       "      <th>Gefitinib</th>\n",
       "      <th>...</th>\n",
       "      <th>CMK</th>\n",
       "      <th>Pyrimethamine</th>\n",
       "      <th>JW-7-52-1</th>\n",
       "      <th>A-443654</th>\n",
       "      <th>GW843682X</th>\n",
       "      <th>MS-275</th>\n",
       "      <th>Parthenolide</th>\n",
       "      <th>MG-132</th>\n",
       "      <th>KIN001-135</th>\n",
       "      <th>TGX221</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BxPC-3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.159708</td>\n",
       "      <td>0.188393</td>\n",
       "      <td>0.436127</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>0.113764</td>\n",
       "      <td>0.249987</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMOE-2</th>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.339814</td>\n",
       "      <td>0.318206</td>\n",
       "      <td>0.281740</td>\n",
       "      <td>0.063808</td>\n",
       "      <td>0.140681</td>\n",
       "      <td>0.101530</td>\n",
       "      <td>0.191210</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022662</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.270791</td>\n",
       "      <td>0.095608</td>\n",
       "      <td>0.139914</td>\n",
       "      <td>0.171747</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFM-223</th>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.334087</td>\n",
       "      <td>0.122671</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.051983</td>\n",
       "      <td>0.186659</td>\n",
       "      <td>0.228797</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.023043</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.102592</td>\n",
       "      <td>0.020338</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.035206</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUGC-3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.095099</td>\n",
       "      <td>0.416792</td>\n",
       "      <td>0.422631</td>\n",
       "      <td>0.266409</td>\n",
       "      <td>0.237811</td>\n",
       "      <td>0.234952</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.028838</td>\n",
       "      <td>0.153002</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OC-314</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.479915</td>\n",
       "      <td>0.390145</td>\n",
       "      <td>0.067738</td>\n",
       "      <td>0.125869</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.110418</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KP-N-S19s</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC-3</th>\n",
       "      <td>0.003515</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.146476</td>\n",
       "      <td>0.400087</td>\n",
       "      <td>0.205247</td>\n",
       "      <td>0.147090</td>\n",
       "      <td>0.298803</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.069181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Panc 08.13</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.152818</td>\n",
       "      <td>0.196279</td>\n",
       "      <td>0.180653</td>\n",
       "      <td>0.090963</td>\n",
       "      <td>0.093197</td>\n",
       "      <td>0.097267</td>\n",
       "      <td>0.018269</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EKVX</th>\n",
       "      <td>0.177238</td>\n",
       "      <td>0.078395</td>\n",
       "      <td>0.078938</td>\n",
       "      <td>0.072213</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.129184</td>\n",
       "      <td>0.095642</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>0.126364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.243635</td>\n",
       "      <td>0.079375</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.177759</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.114431</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.063911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMS-114</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.127677</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.281940</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.191972</td>\n",
       "      <td>0.185916</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.043920</td>\n",
       "      <td>0.285969</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.174841</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.080451</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.028733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>789 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Erlotinib     AICAR  Camptothecin  Vinblastine  Cisplatin  \\\n",
       "BxPC-3      -1.000000  0.159708      0.188393     0.436127   0.154274   \n",
       "KMOE-2       0.002108  0.339814      0.318206     0.281740   0.063808   \n",
       "MFM-223      0.002148  0.334087      0.122671     0.361438   0.051983   \n",
       "NUGC-3      -1.000000  0.095099      0.416792     0.422631   0.266409   \n",
       "OC-314      -1.000000  0.012740      0.479915     0.390145   0.067738   \n",
       "...               ...       ...           ...          ...        ...   \n",
       "KP-N-S19s   -1.000000 -1.000000     -1.000000    -1.000000  -1.000000   \n",
       "BC-3         0.003515 -1.000000     -1.000000    -1.000000  -1.000000   \n",
       "Panc 08.13  -1.000000  0.152818      0.196279     0.180653   0.090963   \n",
       "EKVX         0.177238  0.078395      0.078938     0.072213   0.007225   \n",
       "DMS-114      0.000322  0.127677      0.168317     0.281940   0.092074   \n",
       "\n",
       "            Cytarabine  Docetaxel  Methotrexate      ATRA  Gefitinib  ...  \\\n",
       "BxPC-3        0.113764   0.249987      0.015324  0.015324   0.020293  ...   \n",
       "KMOE-2        0.140681   0.101530      0.191210  0.031229   0.007419  ...   \n",
       "MFM-223       0.186659   0.228797      0.003639  0.023043   0.003639  ...   \n",
       "NUGC-3        0.237811   0.234952      0.011558  0.028838   0.153002  ...   \n",
       "OC-314        0.125869   0.249668      0.110418  0.002214   0.020309  ...   \n",
       "...                ...        ...           ...       ...        ...  ...   \n",
       "KP-N-S19s    -1.000000  -1.000000     -1.000000 -1.000000  -1.000000  ...   \n",
       "BC-3         -1.000000  -1.000000     -1.000000 -1.000000  -1.000000  ...   \n",
       "Panc 08.13    0.093197   0.097267      0.018269  0.010237   0.009405  ...   \n",
       "EKVX          0.003470   0.129184      0.095642  0.111598   0.126364  ...   \n",
       "DMS-114       0.191972   0.185916      0.007135  0.009329   0.020822  ...   \n",
       "\n",
       "                 CMK  Pyrimethamine  JW-7-52-1  A-443654  GW843682X    MS-275  \\\n",
       "BxPC-3     -1.000000      -1.000000  -1.000000 -1.000000  -1.000000 -1.000000   \n",
       "KMOE-2      0.022662       0.025217   0.270791  0.095608   0.139914  0.171747   \n",
       "MFM-223     0.038997       0.006167   0.002185  0.102592   0.020338  0.010874   \n",
       "NUGC-3     -1.000000      -1.000000  -1.000000 -1.000000  -1.000000 -1.000000   \n",
       "OC-314     -1.000000      -1.000000  -1.000000 -1.000000  -1.000000 -1.000000   \n",
       "...              ...            ...        ...       ...        ...       ...   \n",
       "KP-N-S19s  -1.000000      -1.000000  -1.000000 -1.000000  -1.000000 -1.000000   \n",
       "BC-3        0.048227       0.146476   0.400087  0.205247   0.147090  0.298803   \n",
       "Panc 08.13 -1.000000      -1.000000  -1.000000 -1.000000  -1.000000 -1.000000   \n",
       "EKVX        0.020472       0.044047   0.243635  0.079375   0.019859  0.177759   \n",
       "DMS-114     0.002137       0.043920   0.285969  0.075195   0.174841  0.008383   \n",
       "\n",
       "            Parthenolide    MG-132  KIN001-135    TGX221  \n",
       "BxPC-3         -1.000000 -1.000000   -1.000000 -1.000000  \n",
       "KMOE-2          0.026670  0.013904    0.002116  0.000956  \n",
       "MFM-223         0.000970  0.035206    0.007051  0.000323  \n",
       "NUGC-3         -1.000000 -1.000000   -1.000000 -1.000000  \n",
       "OC-314         -1.000000 -1.000000   -1.000000 -1.000000  \n",
       "...                  ...       ...         ...       ...  \n",
       "KP-N-S19s      -1.000000 -1.000000   -1.000000 -1.000000  \n",
       "BC-3            0.023796  0.017219    0.002065  0.069181  \n",
       "Panc 08.13     -1.000000 -1.000000   -1.000000 -1.000000  \n",
       "EKVX            0.014843  0.114431    0.007216  0.063911  \n",
       "DMS-114         0.002135  0.080451    0.002135  0.028733  \n",
       "\n",
       "[789 rows x 139 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = label_r.loc[:,select_drug]!=na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r.columns = adata.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your is gene-cell, mine is cell-gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_r.loc[selected_idx,hvg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_r.loc[selected_idx,select_drug]\n",
    "scaler = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
    "data = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "-9.065550491767716e-18\n"
     ]
    }
   ],
   "source": [
    "print(np.std(data))\n",
    "print(np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675, 3462)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789, 139)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(675, 3462)\n",
      "(675,)\n",
      "(540, 3462) (540,)\n",
      "(135, 3462) (135,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.375997920629374\n",
      "-7.911806694002141\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all data to AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.FloatTensor(X_train).to(device)\n",
    "testData = torch.FloatTensor(X_test).to(device)\n",
    "y = torch.FloatTensor(Y_train.values).to(device)\n",
    "allData = torch.FloatTensor(data).to(device)\n",
    "\n",
    "# construct TensorDataset\n",
    "train_dataset = TensorDataset(trainData, trainData)\n",
    "test_dataset = TensorDataset(testData, testData)\n",
    "all_dataset = TensorDataset(allData, allData)\n",
    "\n",
    "trainDataLoader1 = DataLoader(dataset=train_dataset, batch_size=200, shuffle=False)\n",
    "trainDataLoaderall = DataLoader(dataset=all_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = trainDataLoaderall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEBase(input_dim=data.shape[1],latent_dim=256,hidden_dims=[1024,512,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEBase(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=3462, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (decoder_input): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=3462, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = VAE(dim_au_in=data_r.shape[1],dim_au_out=128)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0001, Training loss=0.40740085\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0002, Training loss=0.39197275\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0003, Training loss=0.37923217\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0004, Training loss=0.36773765\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0005, Training loss=0.35750961\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0006, Training loss=0.34957319\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0007, Training loss=0.34184936\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0008, Training loss=0.33685419\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0009, Training loss=0.33284935\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0010, Training loss=0.32913047\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0011, Training loss=0.32677573\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0012, Training loss=0.32415929\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0013, Training loss=0.32171825\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0014, Training loss=0.32053071\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0015, Training loss=0.31827518\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0016, Training loss=0.31626597\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0017, Training loss=0.31473431\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0018, Training loss=0.31147334\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0019, Training loss=0.31020325\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0020, Training loss=0.30760056\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0021, Training loss=0.30567750\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0022, Training loss=0.30324429\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0023, Training loss=0.30138031\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0024, Training loss=0.29929829\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0025, Training loss=0.29725513\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0026, Training loss=0.29568082\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0027, Training loss=0.29500100\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0028, Training loss=0.29390445\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0029, Training loss=0.29237261\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0030, Training loss=0.29060781\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0031, Training loss=0.28985849\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0032, Training loss=0.28904539\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0033, Training loss=0.28723401\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0034, Training loss=0.28592545\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0035, Training loss=0.28477025\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0036, Training loss=0.28332740\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0037, Training loss=0.28225809\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0038, Training loss=0.28175208\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0039, Training loss=0.28056154\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0040, Training loss=0.27867416\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0041, Training loss=0.27896610\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0042, Training loss=0.27822998\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0043, Training loss=0.27658170\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0044, Training loss=0.27538306\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0045, Training loss=0.27496201\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0046, Training loss=0.27494392\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0047, Training loss=0.27486050\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0048, Training loss=0.27336988\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0049, Training loss=0.27264851\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0050, Training loss=0.27132773\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0051, Training loss=0.27175605\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0052, Training loss=0.27015612\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0053, Training loss=0.26994842\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0054, Training loss=0.26968396\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0055, Training loss=0.26820406\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0056, Training loss=0.26868111\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0057, Training loss=0.26768398\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0058, Training loss=0.26748857\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0059, Training loss=0.26674652\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0060, Training loss=0.26606986\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0061, Training loss=0.26495394\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0062, Training loss=0.26449719\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0063, Training loss=0.26388493\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0064, Training loss=0.26359504\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0065, Training loss=0.26331189\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0066, Training loss=0.26254642\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0067, Training loss=0.26234102\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0068, Training loss=0.26198936\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0069, Training loss=0.26090786\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0070, Training loss=0.25985640\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0071, Training loss=0.25909308\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0072, Training loss=0.25900728\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0073, Training loss=0.25819868\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0074, Training loss=0.25843036\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0075, Training loss=0.25817248\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0076, Training loss=0.25737062\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0077, Training loss=0.25613549\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0078, Training loss=0.25612044\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0079, Training loss=0.25498712\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0080, Training loss=0.25400323\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0081, Training loss=0.25366047\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0082, Training loss=0.25300962\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0083, Training loss=0.25284463\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0084, Training loss=0.25226155\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0085, Training loss=0.25237533\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0086, Training loss=0.25160915\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0087, Training loss=0.25163504\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0088, Training loss=0.25064975\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0089, Training loss=0.25004965\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0090, Training loss=0.25018296\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0091, Training loss=0.24966849\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0092, Training loss=0.24837129\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0093, Training loss=0.24865963\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0094, Training loss=0.24807157\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0095, Training loss=0.24804889\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0096, Training loss=0.24726182\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0097, Training loss=0.24673004\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0098, Training loss=0.24673131\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0099, Training loss=0.24642946\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0100, Training loss=0.24621519\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0101, Training loss=0.24628937\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0102, Training loss=0.24581555\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0103, Training loss=0.24607326\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0104, Training loss=0.24471234\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0105, Training loss=0.24472542\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0106, Training loss=0.24423610\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0107, Training loss=0.24361642\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0108, Training loss=0.24389380\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0109, Training loss=0.24317026\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0110, Training loss=0.24328740\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0111, Training loss=0.24180622\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0112, Training loss=0.24193001\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0113, Training loss=0.24204764\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0114, Training loss=0.24209037\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0115, Training loss=0.24185508\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0116, Training loss=0.24134353\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0117, Training loss=0.24015522\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0118, Training loss=0.24100022\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0119, Training loss=0.24172580\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0120, Training loss=0.24073030\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0121, Training loss=0.24038108\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0122, Training loss=0.23895678\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0123, Training loss=0.23908472\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0124, Training loss=0.23935001\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 3462])\n",
      "Epoch: 0125, Training loss=0.23905975\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0126, Training loss=0.23817959\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0127, Training loss=0.23750272\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0128, Training loss=0.23770466\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0129, Training loss=0.23807044\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0130, Training loss=0.23866501\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0131, Training loss=0.23640449\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0132, Training loss=0.23767094\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0133, Training loss=0.23601930\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0134, Training loss=0.23520868\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0135, Training loss=0.23570113\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0136, Training loss=0.23538831\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0137, Training loss=0.23431671\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0138, Training loss=0.23522481\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0139, Training loss=0.23422036\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0140, Training loss=0.23402764\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0141, Training loss=0.23363015\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0142, Training loss=0.23344955\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0143, Training loss=0.23403206\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0144, Training loss=0.23401693\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0145, Training loss=0.23414405\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0146, Training loss=0.23373210\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0147, Training loss=0.23282509\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0148, Training loss=0.23307049\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0149, Training loss=0.23295034\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0150, Training loss=0.23210610\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0151, Training loss=0.23076189\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0152, Training loss=0.23108916\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0153, Training loss=0.23167719\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0154, Training loss=0.23131287\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0155, Training loss=0.23073298\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0156, Training loss=0.23052970\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0157, Training loss=0.22996403\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0158, Training loss=0.23070216\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0159, Training loss=0.23027007\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0160, Training loss=0.22997071\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0161, Training loss=0.22899304\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0162, Training loss=0.22781116\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0163, Training loss=0.22948679\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0164, Training loss=0.22949599\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0165, Training loss=0.22888550\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0166, Training loss=0.22786532\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0167, Training loss=0.22822897\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0168, Training loss=0.22925623\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0169, Training loss=0.22796921\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0170, Training loss=0.22694792\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0171, Training loss=0.22653958\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0172, Training loss=0.22818853\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0173, Training loss=0.22776473\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0174, Training loss=0.22669114\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0175, Training loss=0.22574528\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0176, Training loss=0.22664398\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0177, Training loss=0.22647272\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0178, Training loss=0.22620788\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0179, Training loss=0.22536634\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0180, Training loss=0.22586919\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0181, Training loss=0.22563061\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0182, Training loss=0.22391188\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0183, Training loss=0.22517465\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0184, Training loss=0.22430047\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0185, Training loss=0.22451492\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0186, Training loss=0.22358064\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 3462])\n",
      "Epoch: 0187, Training loss=0.22415900\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0188, Training loss=0.22567067\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0189, Training loss=0.22426218\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0190, Training loss=0.22470404\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0191, Training loss=0.22235702\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0192, Training loss=0.22378992\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0193, Training loss=0.22283903\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0194, Training loss=0.22132033\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0195, Training loss=0.22270487\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0196, Training loss=0.22263221\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0197, Training loss=0.22165082\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0198, Training loss=0.22176498\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0199, Training loss=0.22214244\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0200, Training loss=0.22190173\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0201, Training loss=0.22112399\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0202, Training loss=0.22132252\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0203, Training loss=0.22073703\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0204, Training loss=0.22327204\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0205, Training loss=0.22002706\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0206, Training loss=0.22104770\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0207, Training loss=0.22053105\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0208, Training loss=0.21980718\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0209, Training loss=0.22014302\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0210, Training loss=0.21973784\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0211, Training loss=0.21953405\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0212, Training loss=0.21902707\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0213, Training loss=0.22069353\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0214, Training loss=0.21813636\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0215, Training loss=0.21894962\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0216, Training loss=0.21829510\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0217, Training loss=0.21887714\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0218, Training loss=0.21798101\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0219, Training loss=0.21962707\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0220, Training loss=0.21813124\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0221, Training loss=0.21674918\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0222, Training loss=0.21896963\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0223, Training loss=0.21648094\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0224, Training loss=0.21551734\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0225, Training loss=0.21602705\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0226, Training loss=0.21628308\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0227, Training loss=0.21633582\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0228, Training loss=0.21576084\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0229, Training loss=0.21659140\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0230, Training loss=0.21565278\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0231, Training loss=0.21554627\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0232, Training loss=0.21566741\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0233, Training loss=0.21506381\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0234, Training loss=0.21462026\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0235, Training loss=0.21428174\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0236, Training loss=0.21427414\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0237, Training loss=0.21378790\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0238, Training loss=0.21374303\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0239, Training loss=0.21441518\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0240, Training loss=0.21419996\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0241, Training loss=0.21337301\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0242, Training loss=0.21359843\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0243, Training loss=0.21233097\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0244, Training loss=0.21321149\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0245, Training loss=0.21301568\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0246, Training loss=0.21226099\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0247, Training loss=0.21356724\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0248, Training loss=0.21250774\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 3462])\n",
      "Epoch: 0249, Training loss=0.21246813\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0250, Training loss=0.21295239\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0251, Training loss=0.21252964\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0252, Training loss=0.21108465\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0253, Training loss=0.21109332\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0254, Training loss=0.21320766\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0255, Training loss=0.20965697\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0256, Training loss=0.21043050\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0257, Training loss=0.21050110\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0258, Training loss=0.21028852\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0259, Training loss=0.21063566\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0260, Training loss=0.20986789\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0261, Training loss=0.21017008\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0262, Training loss=0.20959981\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0263, Training loss=0.20891373\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0264, Training loss=0.20925105\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0265, Training loss=0.20897442\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0266, Training loss=0.20889017\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0267, Training loss=0.20764607\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0268, Training loss=0.20773593\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0269, Training loss=0.20897095\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0270, Training loss=0.21025126\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0271, Training loss=0.20703425\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0272, Training loss=0.21002632\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0273, Training loss=0.20815852\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0274, Training loss=0.20804027\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0275, Training loss=0.20774937\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0276, Training loss=0.20657988\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0277, Training loss=0.20662138\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0278, Training loss=0.20644006\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0279, Training loss=0.20609692\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0280, Training loss=0.20628130\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0281, Training loss=0.20542754\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0282, Training loss=0.20652342\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0283, Training loss=0.20556001\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0284, Training loss=0.20492594\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0285, Training loss=0.20776381\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0286, Training loss=0.20628420\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0287, Training loss=0.20513682\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0288, Training loss=0.20554222\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0289, Training loss=0.20559706\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0290, Training loss=0.20414522\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0291, Training loss=0.20427631\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0292, Training loss=0.20450881\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0293, Training loss=0.20358005\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0294, Training loss=0.20266195\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0295, Training loss=0.20359014\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0296, Training loss=0.20489912\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0297, Training loss=0.20379430\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0298, Training loss=0.20335449\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0299, Training loss=0.20247602\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0300, Training loss=0.20262878\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0301, Training loss=0.20203851\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0302, Training loss=0.20295404\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0303, Training loss=0.20206851\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0304, Training loss=0.20309840\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0305, Training loss=0.20138161\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0306, Training loss=0.20210402\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0307, Training loss=0.20142181\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0308, Training loss=0.20212197\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0309, Training loss=0.20154709\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0310, Training loss=0.20053248\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0311, Training loss=0.20147650\n",
      "torch.Size([200, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0312, Training loss=0.19971353\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0313, Training loss=0.19933626\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0314, Training loss=0.20088661\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0315, Training loss=0.20193540\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0316, Training loss=0.19954519\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0317, Training loss=0.20122343\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0318, Training loss=0.19860698\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0319, Training loss=0.20019467\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0320, Training loss=0.19905785\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0321, Training loss=0.19883934\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0322, Training loss=0.19717421\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0323, Training loss=0.19901672\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0324, Training loss=0.19924538\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0325, Training loss=0.19964024\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0326, Training loss=0.19855778\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0327, Training loss=0.19841221\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0328, Training loss=0.19847280\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0329, Training loss=0.19782220\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0330, Training loss=0.19713026\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0331, Training loss=0.19784349\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0332, Training loss=0.19773275\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0333, Training loss=0.19627556\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0334, Training loss=0.19694638\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0335, Training loss=0.19660819\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0336, Training loss=0.19617762\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0337, Training loss=0.19624956\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0338, Training loss=0.19532984\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0339, Training loss=0.19588296\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0340, Training loss=0.19651623\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0341, Training loss=0.19489826\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0342, Training loss=0.19619089\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0343, Training loss=0.19635397\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0344, Training loss=0.19584674\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0345, Training loss=0.19517034\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0346, Training loss=0.19569547\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0347, Training loss=0.19482785\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0348, Training loss=0.19451055\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0349, Training loss=0.19434324\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0350, Training loss=0.19470948\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0351, Training loss=0.19354618\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0352, Training loss=0.19465958\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0353, Training loss=0.19463302\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0354, Training loss=0.19374444\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0355, Training loss=0.19604805\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0356, Training loss=0.19336219\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0357, Training loss=0.19274367\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0358, Training loss=0.19358103\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0359, Training loss=0.19297902\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0360, Training loss=0.19153695\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0361, Training loss=0.19241171\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0362, Training loss=0.19212385\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0363, Training loss=0.19294882\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0364, Training loss=0.19194198\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0365, Training loss=0.19026929\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0366, Training loss=0.19123355\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0367, Training loss=0.19171594\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0368, Training loss=0.19219960\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0369, Training loss=0.19207500\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0370, Training loss=0.19177437\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0371, Training loss=0.19046076\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0372, Training loss=0.19114470\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0373, Training loss=0.19019400\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0374, Training loss=0.19166002\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0375, Training loss=0.19114691\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0376, Training loss=0.18914108\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0377, Training loss=0.19072828\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0378, Training loss=0.19013917\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0379, Training loss=0.18917264\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0380, Training loss=0.19045407\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0381, Training loss=0.18849675\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0382, Training loss=0.18875088\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0383, Training loss=0.18999806\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0384, Training loss=0.18773428\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0385, Training loss=0.18857408\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0386, Training loss=0.18835230\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0387, Training loss=0.18840183\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0388, Training loss=0.18772341\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0389, Training loss=0.18811044\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0390, Training loss=0.18903218\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0391, Training loss=0.18732956\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0392, Training loss=0.18975064\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0393, Training loss=0.18800822\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0394, Training loss=0.18862535\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0395, Training loss=0.18863197\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0396, Training loss=0.18432552\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0397, Training loss=0.18747686\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0398, Training loss=0.18961160\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0399, Training loss=0.18785936\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0400, Training loss=0.18772680\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0401, Training loss=0.18964987\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0402, Training loss=0.18603417\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0403, Training loss=0.18505368\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0404, Training loss=0.18796316\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0405, Training loss=0.18590555\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0406, Training loss=0.18701200\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0407, Training loss=0.18525299\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0408, Training loss=0.18638745\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0409, Training loss=0.18586722\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0410, Training loss=0.18662290\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0411, Training loss=0.18546355\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0412, Training loss=0.18562853\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0413, Training loss=0.18470173\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0414, Training loss=0.18489625\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0415, Training loss=0.18535601\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0416, Training loss=0.18390365\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0417, Training loss=0.18476866\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0418, Training loss=0.18594976\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0419, Training loss=0.18528926\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0420, Training loss=0.18478009\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0421, Training loss=0.18341765\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0422, Training loss=0.18413442\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0423, Training loss=0.18363015\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0424, Training loss=0.18533419\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0425, Training loss=0.18449897\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0426, Training loss=0.18334122\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0427, Training loss=0.18374024\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0428, Training loss=0.18273973\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0429, Training loss=0.18233190\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0430, Training loss=0.18443441\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0431, Training loss=0.18370306\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0432, Training loss=0.18186498\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0433, Training loss=0.18276665\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0434, Training loss=0.18200877\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0435, Training loss=0.18331996\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0436, Training loss=0.18213660\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0437, Training loss=0.18299472\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0438, Training loss=0.18226419\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0439, Training loss=0.18136422\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0440, Training loss=0.18172385\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0441, Training loss=0.18081677\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0442, Training loss=0.18016757\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0443, Training loss=0.18076363\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0444, Training loss=0.18234502\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0445, Training loss=0.18106773\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0446, Training loss=0.18211007\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0447, Training loss=0.18118012\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0448, Training loss=0.18185316\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0449, Training loss=0.18118089\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0450, Training loss=0.17948312\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0451, Training loss=0.18078941\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0452, Training loss=0.17985517\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0453, Training loss=0.18000196\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0454, Training loss=0.17889142\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0455, Training loss=0.17844348\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0456, Training loss=0.18037170\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0457, Training loss=0.17944497\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0458, Training loss=0.18024813\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0459, Training loss=0.17746018\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0460, Training loss=0.17934054\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0461, Training loss=0.17872518\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0462, Training loss=0.17939673\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0463, Training loss=0.17953074\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0464, Training loss=0.17731006\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0465, Training loss=0.17732210\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0466, Training loss=0.17964661\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0467, Training loss=0.17876472\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0468, Training loss=0.17888917\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0469, Training loss=0.17880619\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0470, Training loss=0.17709523\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0471, Training loss=0.17860493\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0472, Training loss=0.17782424\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0473, Training loss=0.17606637\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0474, Training loss=0.17759220\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0475, Training loss=0.17894676\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0476, Training loss=0.17726184\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0477, Training loss=0.17844146\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0478, Training loss=0.17749892\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0479, Training loss=0.17508191\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0480, Training loss=0.17579311\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0481, Training loss=0.17825399\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0482, Training loss=0.17722447\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0483, Training loss=0.17488162\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0484, Training loss=0.17793123\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0485, Training loss=0.17508101\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0486, Training loss=0.17524791\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0487, Training loss=0.17586271\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0488, Training loss=0.17775108\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0489, Training loss=0.17594175\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0490, Training loss=0.17643870\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0491, Training loss=0.17410265\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0492, Training loss=0.17649466\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0493, Training loss=0.17600283\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0494, Training loss=0.17457877\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0495, Training loss=0.17362878\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0496, Training loss=0.17328927\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0497, Training loss=0.17346427\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0498, Training loss=0.17408587\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0499, Training loss=0.17454344\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([200, 3462])\n",
      "torch.Size([75, 3462])\n",
      "Epoch: 0500, Training loss=0.17398685\n"
     ]
    }
   ],
   "source": [
    "loss_train = np.zeros((epochs, 1))\n",
    "\n",
    "# Train autoencoder\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 不需要label，所以用一个占位符\"_\"代替\n",
    "    for batchidx, (x, _) in enumerate(trainDataLoaderall):\n",
    "        x.requires_grad_(True)\n",
    "        # encode and decode \n",
    "        output = model(x)\n",
    "        # compute loss\n",
    "        print(output.shape)\n",
    "        loss = loss_function(output, x)      \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    loss_train[epoch,0] = loss.item()  \n",
    "    print('Epoch: %04d, Training loss=%.8f' %\n",
    "          (epoch+1, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''saved/models/ae.pth')' was not found in history, as a file, url, nor in the user namespace.\n"
     ]
    }
   ],
   "source": [
    "save(model.state_dict(), 'saved/models/ae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_batch = model(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2155, device='cuda:0', grad_fn=<SmoothL1LossBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(recon_batch,trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = model.encode(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = train_embeddings.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.001)\n",
    "clf.fit(feature, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFrg = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "RFrg.fit(feature, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeature = model.encode(testData)\n",
    "lasso = clf.predict(testFeature.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfresult = RFrg.predict(testFeature.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.07412733740147"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(lasso,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8667001867915856"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(rfresult,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.010893, 0.003969, 0.126364, 0.04815 , 0.013301, 0.003975,\n",
       "       0.006658, 0.236411, 0.024986, 0.112077, 0.004105, 0.007248,\n",
       "       0.015496, 0.079042, 0.066385, 0.006305, 0.006078, 0.025742,\n",
       "       0.030093, 0.024503, 0.011125, 0.037697, 0.012029, 0.003817,\n",
       "       0.010667, 0.067386, 0.057037, 0.006329, 0.067224, 0.003564,\n",
       "       0.186092, 0.108377, 0.101198, 0.029871, 0.02189 , 0.043306,\n",
       "       0.12798 , 0.005638, 0.038664, 0.002193, 0.005611, 0.157488,\n",
       "       0.007132, 0.006106, 0.008437, 0.031169, 0.054449, 0.006736,\n",
       "       0.016306, 0.003624, 0.093631, 0.011592, 0.010451, 0.003869,\n",
       "       0.011615, 0.189386, 0.003639, 0.023794, 0.020825, 0.036415,\n",
       "       0.00255 , 0.005367, 0.018914, 0.013027, 0.185878, 0.003549,\n",
       "       0.004383, 0.007288, 0.012238, 0.019928, 0.075604, 0.01131 ,\n",
       "       0.006595, 0.00253 , 0.005594, 0.018333, 0.015419, 0.010771,\n",
       "       0.008096, 0.03138 , 0.043866, 0.014501, 0.002152, 0.015858,\n",
       "       0.142685, 0.134998, 0.006991, 0.049048, 0.033088, 0.005561,\n",
       "       0.012738, 0.018554, 0.017699, 0.141754, 0.010312, 0.004757,\n",
       "       0.00994 , 0.035553, 0.006461, 0.053599, 0.029555, 0.115657,\n",
       "       0.003604, 0.029185, 0.034422, 0.028011, 0.004901, 0.081803,\n",
       "       0.014341, 0.007389, 0.043371, 0.0064  , 0.093948, 0.010454,\n",
       "       0.017118, 0.00423 , 0.010077, 0.011115, 0.004962, 0.016636,\n",
       "       0.030657, 0.010251, 0.007557, 0.194723, 0.076808, 0.007164,\n",
       "       0.05563 , 0.151063, 0.041997, 0.016026, 0.006891, 0.003589,\n",
       "       0.004219, 0.022708, 0.056148])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04544396, 0.06734093, 0.06377047, 0.02340427, 0.03321962,\n",
       "       0.03108255, 0.04430354, 0.08361159, 0.085765  , 0.07418036,\n",
       "       0.01756385, 0.04774304, 0.02550264, 0.02741602, 0.05130644,\n",
       "       0.02950179, 0.0285139 , 0.03134224, 0.03029437, 0.02092909,\n",
       "       0.01270665, 0.02905975, 0.03553276, 0.05071436, 0.0337828 ,\n",
       "       0.04824643, 0.07182165, 0.02350863, 0.04646199, 0.02535163,\n",
       "       0.03639966, 0.05288374, 0.09163362, 0.09985648, 0.04434686,\n",
       "       0.03048915, 0.04460238, 0.01941024, 0.02975804, 0.03917842,\n",
       "       0.0538914 , 0.03354143, 0.03364884, 0.01611548, 0.0274551 ,\n",
       "       0.02108319, 0.01297739, 0.05200652, 0.03115727, 0.02409462,\n",
       "       0.05304045, 0.1028788 , 0.03304246, 0.01428098, 0.01918673,\n",
       "       0.06179765, 0.02147982, 0.02919494, 0.01954293, 0.0367334 ,\n",
       "       0.05657205, 0.04624026, 0.03179698, 0.03727589, 0.09738907,\n",
       "       0.01895641, 0.03559419, 0.01458342, 0.02372696, 0.04588088,\n",
       "       0.09081751, 0.02690984, 0.06742653, 0.02153077, 0.04761006,\n",
       "       0.07466816, 0.02428273, 0.01579552, 0.02172701, 0.03769386,\n",
       "       0.03139074, 0.01496463, 0.03670504, 0.04877022, 0.0179667 ,\n",
       "       0.05829638, 0.03593884, 0.02385187, 0.03557176, 0.05994315,\n",
       "       0.08595331, 0.01511323, 0.04028316, 0.06012827, 0.02540863,\n",
       "       0.02733378, 0.03256662, 0.04782118, 0.029644  , 0.02273978,\n",
       "       0.01907311, 0.0232013 , 0.02398724, 0.03610921, 0.06685306,\n",
       "       0.02501294, 0.01525824, 0.05164896, 0.02345663, 0.02055456,\n",
       "       0.0301946 , 0.04477941, 0.0173175 , 0.09311533, 0.01701208,\n",
       "       0.02690082, 0.04019271, 0.02980704, 0.03551496, 0.01068708,\n",
       "       0.01943637, 0.0152533 , 0.02655494, 0.0212172 , 0.0703501 ,\n",
       "       0.02389532, 0.03570049, 0.0118557 , 0.06729071, 0.02295817,\n",
       "       0.03405995, 0.01328693, 0.01900666, 0.02494085, 0.06566166])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], label=\"label\")\n",
    "plt.legend()\n",
    "plt.savefig(\"saved/figures/tsne_vae_gdsc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data type conversion\n",
    "B_feature = torch.FloatTensor(feature).to(device)\n",
    "y = torch.FloatTensor(Y_train.values).to(device)\n",
    "# construct TensorDataset\n",
    "b_data = TensorDataset(B_feature, y)\n",
    "trainDataLoader2 = DataLoader(dataset=b_data, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization DNN model\n",
    "\n",
    "predictor = DNN(128, dim_dnn_out).to(device)\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=1e-3,betas=(0.9,0.99))\n",
    "#loss1-softmax\n",
    "loss_func = nn.MSELoss().to(device)\n",
    "#loss2-sigmoid\n",
    "#loss_func = nn.BCELoss()\n",
    "#loss3-sigmoid\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "#criterion = torch.nn.MSELoss(size_average=True)\n",
    "#criterion = torch.nn.BCELoss(size_average=True) # Defined loss function\n",
    "#optimizer = optim.Adm(model.parameters(), lr=0.01) # Defined optimizer\n",
    "loss_train = np.zeros((epochs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "for epoch in range(EPOCH):\n",
    "    print('Epoch: ',epoch)\n",
    "    for step,(batch_x,batch_y) in enumerate(trainDataLoader2):\n",
    "        b_x = Variable(batch_x)\n",
    "        b_y = Variable(batch_y)\n",
    "        # predict label\n",
    "        output = predictor(b_x)\n",
    "        # b_y=F.sigmoid(b_y) \n",
    "        \n",
    "        #print\n",
    "        #print(output)\n",
    "        #print(b_y)\n",
    "        # compute loss\n",
    "        loss = loss_func(output,b_y)\n",
    "        #loss = criterion(output, b_y)\n",
    "        \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_train[epoch,0] = loss.item()  \n",
    "    print('Epoch: %04d, Training loss=%.8f' %\n",
    "          (epoch+1, loss.item())) \n",
    "\n",
    "# Save model\n",
    "torch.save(predictor.state_dict(), 'saved/models/DNN_GDSC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredict = predictor(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(testpredict.detach().cpu().numpy(),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(testpredict.detach().cpu().numpy(),Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
