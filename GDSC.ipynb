{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "#import scipy.io as sio\n",
    "\n",
    "from models import AE\n",
    "from models import DNN\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "epochs = 500 #200,500,1000\n",
    "dim_au_in = 20049\n",
    "dim_au_out = 512 #8, 16, 32, 64, 128, 256,512\n",
    "dim_dnn_in = dim_au_out\n",
    "dim_dnn_out=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r=pd.read_csv('data/GDSCexpression.csv',index_col=0)\n",
    "label_r=pd.read_csv('data/GDSClabel.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_r=label_r.fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your is gene-cell, mine is cell-gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_r.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_r\n",
    "label = label_r.iloc[:,10]\n",
    "scaler = preprocessing.StandardScaler(with_mean=True, with_std=True)\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999997\n",
      "6.316789844568889e-19\n"
     ]
    }
   ],
   "source": [
    "print(np.std(data))\n",
    "print(np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789, 11833)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789, 139)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 11833)\n",
      "(789,)\n",
      "(631, 11833) (631,)\n",
      "(158, 11833) (158,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.78951596267762\n",
      "-17.277718272630676\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all data to AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.FloatTensor(X_train).to(device)\n",
    "testData = torch.FloatTensor(X_test).to(device)\n",
    "y = torch.FloatTensor(Y_train.values).to(device)\n",
    "allData = torch.FloatTensor(data).to(device)\n",
    "\n",
    "# construct TensorDataset\n",
    "train_dataset = TensorDataset(trainData, trainData)\n",
    "test_dataset = TensorDataset(testData, testData)\n",
    "all_dataset = TensorDataset(allData, allData)\n",
    "\n",
    "trainDataLoader1 = DataLoader(dataset=train_dataset, batch_size=200, shuffle=False)\n",
    "trainDataLoaderall = DataLoader(dataset=all_dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "#autoencoder = AE(dim=train_dataset.shape[1]).to(device)\n",
    "autoencoder = AE(dim_au_in = X_train.shape[1],dim_au_out=dim_au_out).to(device)\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "#loss1\n",
    "loss_func = nn.SmoothL1Loss().to(device)\n",
    "#loss2\n",
    "#loss_func = nn.BCELoss()\n",
    "loss_train = np.zeros((epochs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0001, Training loss=0.37845567\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0002, Training loss=0.37417948\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0003, Training loss=0.37675849\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0004, Training loss=0.37448874\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0005, Training loss=0.36873662\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0006, Training loss=0.37881958\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0007, Training loss=0.38113067\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0008, Training loss=0.37102729\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0009, Training loss=0.37375990\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0010, Training loss=0.37982020\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0011, Training loss=0.37145457\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0012, Training loss=0.37809852\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0013, Training loss=0.37729952\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0014, Training loss=0.36825949\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0015, Training loss=0.36721987\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0016, Training loss=0.36507612\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0017, Training loss=0.37139672\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0018, Training loss=0.36887005\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0019, Training loss=0.36664137\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0020, Training loss=0.36844006\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0021, Training loss=0.35994032\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0022, Training loss=0.36514214\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0023, Training loss=0.36317322\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0024, Training loss=0.36846679\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0025, Training loss=0.35871065\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0026, Training loss=0.36403370\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0027, Training loss=0.35927346\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0028, Training loss=0.36124167\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0029, Training loss=0.36014864\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0030, Training loss=0.36018431\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0031, Training loss=0.35916561\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0032, Training loss=0.35731092\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0033, Training loss=0.35843971\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0034, Training loss=0.35461918\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0035, Training loss=0.35168242\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0036, Training loss=0.36035991\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0037, Training loss=0.35037434\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0038, Training loss=0.35043821\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0039, Training loss=0.34224981\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0040, Training loss=0.34003708\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0041, Training loss=0.34447372\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0042, Training loss=0.33770221\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0043, Training loss=0.33595452\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0044, Training loss=0.33260819\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0045, Training loss=0.33084100\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0046, Training loss=0.33029968\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0047, Training loss=0.32906622\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0048, Training loss=0.31819868\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0049, Training loss=0.32641014\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0050, Training loss=0.32341266\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0051, Training loss=0.31437248\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0052, Training loss=0.31442648\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0053, Training loss=0.31118715\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0054, Training loss=0.31283814\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0055, Training loss=0.30707493\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0056, Training loss=0.30505988\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0057, Training loss=0.30558175\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0058, Training loss=0.30343452\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0059, Training loss=0.30240539\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0060, Training loss=0.29740468\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0061, Training loss=0.30632782\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0062, Training loss=0.29584876\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0063, Training loss=0.29808307\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0064, Training loss=0.29152665\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0065, Training loss=0.29391596\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0066, Training loss=0.29208231\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0067, Training loss=0.29070157\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0068, Training loss=0.29494298\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0069, Training loss=0.28896961\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0070, Training loss=0.28601724\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0071, Training loss=0.28742796\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0072, Training loss=0.28441438\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0073, Training loss=0.28162426\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0074, Training loss=0.28421766\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0075, Training loss=0.28919125\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0076, Training loss=0.28766134\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0077, Training loss=0.28163621\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0078, Training loss=0.28192759\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0079, Training loss=0.28449810\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0080, Training loss=0.27787969\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0081, Training loss=0.28084129\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0082, Training loss=0.28422806\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0083, Training loss=0.28272501\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0084, Training loss=0.28059739\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0085, Training loss=0.27944383\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0086, Training loss=0.27801085\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0087, Training loss=0.28068748\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0088, Training loss=0.27229002\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0089, Training loss=0.27726513\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0090, Training loss=0.28427106\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0091, Training loss=0.27787197\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0092, Training loss=0.27580735\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0093, Training loss=0.27414241\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0094, Training loss=0.28166667\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0095, Training loss=0.27967185\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0096, Training loss=0.27727574\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0097, Training loss=0.27880585\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0098, Training loss=0.27627471\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0099, Training loss=0.27490032\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0100, Training loss=0.27754867\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0101, Training loss=0.27483881\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0102, Training loss=0.27343544\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0103, Training loss=0.27800542\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0104, Training loss=0.28048310\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0105, Training loss=0.27573180\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0106, Training loss=0.27995226\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0107, Training loss=0.27982298\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0108, Training loss=0.27595988\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0109, Training loss=0.27351695\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0110, Training loss=0.27803990\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0111, Training loss=0.27449638\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0112, Training loss=0.27499014\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0113, Training loss=0.28001347\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0114, Training loss=0.27840665\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0115, Training loss=0.28044820\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0116, Training loss=0.27414867\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0117, Training loss=0.26932773\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0118, Training loss=0.27572784\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0119, Training loss=0.27404046\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0120, Training loss=0.27295655\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0121, Training loss=0.27498516\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0122, Training loss=0.27210140\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0123, Training loss=0.27626708\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0124, Training loss=0.27052471\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0125, Training loss=0.27441546\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0126, Training loss=0.27622101\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0127, Training loss=0.27181399\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0128, Training loss=0.27775621\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0129, Training loss=0.27411723\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0130, Training loss=0.27333769\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0131, Training loss=0.26816267\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0132, Training loss=0.27542096\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0133, Training loss=0.27596307\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0134, Training loss=0.26885572\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0135, Training loss=0.27324224\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0136, Training loss=0.27387890\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0137, Training loss=0.27037352\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0138, Training loss=0.27308410\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0139, Training loss=0.27431417\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0140, Training loss=0.27127501\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0141, Training loss=0.26696956\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0142, Training loss=0.27553445\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0143, Training loss=0.26434880\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0144, Training loss=0.26965463\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0145, Training loss=0.27109316\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0146, Training loss=0.27196044\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0147, Training loss=0.26869822\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0148, Training loss=0.27362922\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0149, Training loss=0.27059832\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0150, Training loss=0.27522773\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0151, Training loss=0.27255723\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0152, Training loss=0.27148318\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0153, Training loss=0.27224350\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0154, Training loss=0.26921335\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0155, Training loss=0.27925083\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0156, Training loss=0.27027288\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0157, Training loss=0.27112639\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0158, Training loss=0.26750538\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0159, Training loss=0.27255821\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0160, Training loss=0.27194747\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0161, Training loss=0.27204508\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0162, Training loss=0.27234396\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0163, Training loss=0.26709667\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0164, Training loss=0.27223241\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0165, Training loss=0.27329370\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0166, Training loss=0.26995113\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0167, Training loss=0.26765022\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0168, Training loss=0.26813033\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0169, Training loss=0.26824391\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0170, Training loss=0.27320638\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0171, Training loss=0.27281880\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0172, Training loss=0.27106446\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0173, Training loss=0.27231294\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0174, Training loss=0.27433193\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0175, Training loss=0.27432749\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0176, Training loss=0.26429573\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0177, Training loss=0.27146220\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0178, Training loss=0.26869053\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0179, Training loss=0.27139392\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0180, Training loss=0.27191427\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0181, Training loss=0.27088499\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0182, Training loss=0.27317441\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0183, Training loss=0.26762256\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0184, Training loss=0.27096280\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0185, Training loss=0.26798484\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0186, Training loss=0.27404717\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0187, Training loss=0.26777554\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0188, Training loss=0.26911339\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0189, Training loss=0.26807228\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0190, Training loss=0.27204707\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0191, Training loss=0.26710269\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0192, Training loss=0.26891944\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0193, Training loss=0.26761287\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0194, Training loss=0.27037162\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0195, Training loss=0.27524960\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0196, Training loss=0.26728189\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0197, Training loss=0.27031443\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0198, Training loss=0.27113730\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0199, Training loss=0.26087713\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0200, Training loss=0.26953882\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0201, Training loss=0.26894781\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0202, Training loss=0.27064627\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0203, Training loss=0.26617736\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0204, Training loss=0.26995707\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0205, Training loss=0.26643899\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0206, Training loss=0.26538205\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0207, Training loss=0.26224899\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0208, Training loss=0.26850516\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0209, Training loss=0.26828992\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0210, Training loss=0.26241693\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0211, Training loss=0.26268849\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0212, Training loss=0.27220777\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0213, Training loss=0.27013460\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0214, Training loss=0.26758328\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0215, Training loss=0.26715189\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0216, Training loss=0.26522347\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0217, Training loss=0.26669019\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0218, Training loss=0.26884145\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0219, Training loss=0.26963502\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0220, Training loss=0.26406708\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0221, Training loss=0.26315081\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0222, Training loss=0.26758355\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0223, Training loss=0.26389465\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0224, Training loss=0.26929376\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0225, Training loss=0.26437145\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0226, Training loss=0.26137328\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0227, Training loss=0.26659486\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0228, Training loss=0.26686409\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0229, Training loss=0.26330778\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0230, Training loss=0.26153150\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0231, Training loss=0.26188543\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0232, Training loss=0.26871216\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0233, Training loss=0.26690704\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0234, Training loss=0.26540026\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0235, Training loss=0.26404160\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0236, Training loss=0.27081007\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0237, Training loss=0.26619038\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0238, Training loss=0.26471353\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0239, Training loss=0.26178256\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0240, Training loss=0.26629633\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0241, Training loss=0.26801470\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0242, Training loss=0.26637670\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0243, Training loss=0.26568466\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0244, Training loss=0.26361832\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0245, Training loss=0.26774016\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0246, Training loss=0.27065924\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0247, Training loss=0.26314250\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0248, Training loss=0.26251328\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0249, Training loss=0.26369962\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0250, Training loss=0.26338050\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0251, Training loss=0.26533577\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0252, Training loss=0.26952973\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0253, Training loss=0.26996756\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0254, Training loss=0.26362887\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0255, Training loss=0.26381299\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0256, Training loss=0.26221469\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0257, Training loss=0.26078066\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0258, Training loss=0.26416236\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0259, Training loss=0.26325715\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0260, Training loss=0.26501170\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0261, Training loss=0.26000199\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0262, Training loss=0.26530570\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0263, Training loss=0.26329422\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0264, Training loss=0.26271778\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0265, Training loss=0.26880705\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0266, Training loss=0.26485503\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0267, Training loss=0.26175070\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0268, Training loss=0.26180041\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0269, Training loss=0.26102585\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0270, Training loss=0.26149863\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0271, Training loss=0.26400179\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0272, Training loss=0.26254061\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0273, Training loss=0.26505139\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0274, Training loss=0.25921777\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0275, Training loss=0.25831491\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0276, Training loss=0.26217881\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0277, Training loss=0.26198909\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0278, Training loss=0.26351872\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0279, Training loss=0.25556207\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0280, Training loss=0.25801051\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0281, Training loss=0.26352638\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0282, Training loss=0.26097637\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0283, Training loss=0.26212314\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0284, Training loss=0.26341334\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0285, Training loss=0.26260117\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0286, Training loss=0.26123801\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0287, Training loss=0.26027974\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0288, Training loss=0.25953773\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0289, Training loss=0.26014134\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0290, Training loss=0.26171243\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0291, Training loss=0.26210922\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0292, Training loss=0.25946409\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0293, Training loss=0.25858095\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0294, Training loss=0.25680837\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0295, Training loss=0.26346919\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0296, Training loss=0.26133499\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0297, Training loss=0.26076898\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0298, Training loss=0.26089776\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0299, Training loss=0.26201198\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0300, Training loss=0.25991443\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0301, Training loss=0.25912178\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0302, Training loss=0.25844508\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0303, Training loss=0.26016200\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0304, Training loss=0.26125082\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0305, Training loss=0.25654250\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0306, Training loss=0.25981590\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0307, Training loss=0.26114640\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0308, Training loss=0.25861487\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0309, Training loss=0.26333871\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0310, Training loss=0.26135975\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0311, Training loss=0.26022246\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0312, Training loss=0.25888205\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0313, Training loss=0.26440853\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0314, Training loss=0.26090327\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0315, Training loss=0.25747350\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0316, Training loss=0.26082817\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0317, Training loss=0.26325193\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0318, Training loss=0.26054701\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0319, Training loss=0.25807467\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0320, Training loss=0.25626519\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0321, Training loss=0.26087490\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0322, Training loss=0.26101449\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0323, Training loss=0.26110157\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0324, Training loss=0.25900155\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0325, Training loss=0.25878111\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0326, Training loss=0.26005453\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0327, Training loss=0.26293570\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0328, Training loss=0.25997117\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0329, Training loss=0.25953317\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0330, Training loss=0.25664932\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0331, Training loss=0.25547338\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0332, Training loss=0.26060957\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0333, Training loss=0.25850952\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0334, Training loss=0.25676405\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0335, Training loss=0.25782168\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0336, Training loss=0.26267019\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0337, Training loss=0.26195902\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0338, Training loss=0.25781688\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0339, Training loss=0.25937954\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0340, Training loss=0.25281048\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0341, Training loss=0.25830898\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0342, Training loss=0.25361669\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0343, Training loss=0.25729072\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0344, Training loss=0.25962934\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0345, Training loss=0.25193644\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0346, Training loss=0.25506744\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0347, Training loss=0.25891054\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0348, Training loss=0.25605169\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0349, Training loss=0.25802973\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0350, Training loss=0.25842389\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0351, Training loss=0.25737911\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0352, Training loss=0.26328793\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0353, Training loss=0.25819221\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0354, Training loss=0.25716484\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0355, Training loss=0.25604150\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0356, Training loss=0.25664040\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0357, Training loss=0.26029509\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0358, Training loss=0.25615850\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0359, Training loss=0.25001425\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0360, Training loss=0.25911897\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0361, Training loss=0.25700635\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0362, Training loss=0.25563586\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0363, Training loss=0.26097968\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0364, Training loss=0.25545672\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0365, Training loss=0.25036085\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0366, Training loss=0.25629595\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0367, Training loss=0.25577727\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0368, Training loss=0.25824898\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0369, Training loss=0.25575188\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0370, Training loss=0.25518274\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0371, Training loss=0.25672358\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0372, Training loss=0.25294444\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0373, Training loss=0.25328216\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0374, Training loss=0.25268042\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0375, Training loss=0.25401425\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0376, Training loss=0.26013771\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0377, Training loss=0.25654048\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0378, Training loss=0.25074381\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0379, Training loss=0.25561473\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0380, Training loss=0.25720167\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0381, Training loss=0.26167721\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0382, Training loss=0.25672108\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0383, Training loss=0.26100188\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0384, Training loss=0.25878477\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0385, Training loss=0.25695804\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0386, Training loss=0.25569913\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0387, Training loss=0.25704128\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0388, Training loss=0.25394154\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0389, Training loss=0.26073778\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0390, Training loss=0.25541264\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0391, Training loss=0.25561786\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0392, Training loss=0.25794575\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0393, Training loss=0.25153229\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0394, Training loss=0.25515357\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0395, Training loss=0.25634128\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0396, Training loss=0.25565413\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0397, Training loss=0.24877371\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0398, Training loss=0.25417283\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0399, Training loss=0.25457498\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0400, Training loss=0.25929022\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0401, Training loss=0.25655216\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0402, Training loss=0.25591180\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0403, Training loss=0.25258747\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0404, Training loss=0.25433484\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0405, Training loss=0.25533438\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0406, Training loss=0.25297442\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0407, Training loss=0.25386095\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0408, Training loss=0.25751865\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0409, Training loss=0.25431490\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0410, Training loss=0.25676507\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0411, Training loss=0.25622126\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0412, Training loss=0.25375283\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0413, Training loss=0.25246733\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0414, Training loss=0.25747412\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0415, Training loss=0.25877988\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0416, Training loss=0.25144780\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0417, Training loss=0.25562263\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0418, Training loss=0.25810325\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0419, Training loss=0.25146052\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0420, Training loss=0.26064262\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0421, Training loss=0.25432584\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0422, Training loss=0.25614005\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0423, Training loss=0.25749758\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0424, Training loss=0.25442120\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0425, Training loss=0.25709635\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0426, Training loss=0.25370604\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0427, Training loss=0.25351605\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0428, Training loss=0.24937607\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0429, Training loss=0.25160646\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0430, Training loss=0.25381026\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0431, Training loss=0.25595006\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0432, Training loss=0.25300825\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0433, Training loss=0.25356048\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0434, Training loss=0.24866644\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0435, Training loss=0.25220111\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0436, Training loss=0.25213996\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0437, Training loss=0.25606650\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0438, Training loss=0.25550160\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0439, Training loss=0.25294146\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0440, Training loss=0.24949965\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0441, Training loss=0.25817943\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0442, Training loss=0.25549954\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0443, Training loss=0.25659952\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0444, Training loss=0.24831870\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0445, Training loss=0.25452566\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0446, Training loss=0.25756991\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0447, Training loss=0.25693396\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0448, Training loss=0.24996325\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0449, Training loss=0.25495502\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0450, Training loss=0.25151560\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0451, Training loss=0.25639021\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0452, Training loss=0.25126070\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0453, Training loss=0.25914964\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0454, Training loss=0.25238192\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0455, Training loss=0.25363553\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0456, Training loss=0.25368407\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0457, Training loss=0.25179124\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0458, Training loss=0.25177699\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0459, Training loss=0.25352809\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0460, Training loss=0.24958609\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0461, Training loss=0.24956705\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0462, Training loss=0.25389415\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0463, Training loss=0.25239772\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0464, Training loss=0.25056803\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0465, Training loss=0.25120336\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0466, Training loss=0.25145286\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0467, Training loss=0.25216255\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0468, Training loss=0.25335455\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0469, Training loss=0.25433934\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0470, Training loss=0.24986455\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0471, Training loss=0.24836417\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0472, Training loss=0.25531745\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0473, Training loss=0.25391713\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0474, Training loss=0.25621116\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0475, Training loss=0.25256333\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0476, Training loss=0.25015417\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0477, Training loss=0.25295240\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0478, Training loss=0.24937364\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0479, Training loss=0.25120503\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0480, Training loss=0.25301781\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0481, Training loss=0.25151235\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0482, Training loss=0.25134054\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0483, Training loss=0.25000939\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0484, Training loss=0.25273153\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0485, Training loss=0.25271139\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0486, Training loss=0.25524902\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0487, Training loss=0.25959173\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0488, Training loss=0.25280523\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0489, Training loss=0.25225005\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0490, Training loss=0.25307196\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0491, Training loss=0.25085956\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0492, Training loss=0.25630432\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0493, Training loss=0.25133333\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0494, Training loss=0.25377616\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0495, Training loss=0.25042403\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0496, Training loss=0.25352508\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0497, Training loss=0.25260597\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0498, Training loss=0.25408149\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0499, Training loss=0.25509384\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([200, 512]) torch.Size([200, 11833])\n",
      "torch.Size([189, 512]) torch.Size([189, 11833])\n",
      "Epoch: 0500, Training loss=0.25198171\n"
     ]
    }
   ],
   "source": [
    "# Train autoencoder\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 不需要label，所以用一个占位符\"_\"代替\n",
    "    for batchidx, (x, _) in enumerate(trainDataLoaderall):\n",
    "        x.requires_grad_(True)\n",
    "        # encode and decode \n",
    "        decoded, encoded = autoencoder(x)\n",
    "        # compute loss\n",
    "        print(encoded.shape, decoded.shape)\n",
    "        loss = loss_func(decoded, x)      \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    loss_train[epoch,0] = loss.item()  \n",
    "    print('Epoch: %04d, Training loss=%.8f' %\n",
    "          (epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder.state_dict(), 'saved/models/AE_GDSC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "_, encodedTrainData = autoencoder(trainData)\n",
    "featureTensor = encodedTrainData.double()\n",
    "feature = featureTensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 512)\n"
     ]
    }
   ],
   "source": [
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.98830223, -14.46842289,  11.41365528, ...,  -9.24433613,\n",
       "          3.9695642 ,  12.58987141],\n",
       "       [-11.73050022,  -0.86351913,  -1.08967912, ...,  15.4855442 ,\n",
       "         -6.06346178, -34.49357986],\n",
       "       [  1.59288394,  25.82977676,  -7.95423126, ...,  18.5807991 ,\n",
       "         -1.46764755,  14.93826675],\n",
       "       ...,\n",
       "       [ -3.00393653, -12.83430099,  -1.45899022, ...,   0.44991681,\n",
       "         -0.48832205,  14.80224895],\n",
       "       [ 11.41576099,   3.00179625,  14.86866474, ...,  -3.67698646,\n",
       "         -7.11067963,   7.3389039 ],\n",
       "       [-22.35505295,  -0.05884793,  -8.42875862, ...,   8.44301128,\n",
       "         -1.06642449, -12.4538517 ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(feature, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,testFeature = autoencoder(testData)\n",
    "lasso = clf.predict(testFeature.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.107482739562604"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(lasso,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 631 samples in 0.030s...\n",
      "[t-SNE] Computed neighbors for 631 samples in 0.267s...\n",
      "[t-SNE] Computed conditional probabilities for sample 631 / 631\n",
      "[t-SNE] Mean sigma: 114.791064\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.070099\n",
      "[t-SNE] KL divergence after 300 iterations: 1.423183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.3864455,  -9.126111 ],\n",
       "       [-10.78426  ,  -3.0034292],\n",
       "       [ -5.8190293,   1.8749901],\n",
       "       ...,\n",
       "       [  1.2086612,  -3.6844873],\n",
       "       [ -3.5691628,   1.2370542],\n",
       "       [ -2.0948431,  14.303509 ]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], label=\"label\")\n",
    "plt.legend()\n",
    "plt.savefig(\"saved/figures/tsne_ae_gdsc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data type conversion\n",
    "B_feature = torch.FloatTensor(feature).to(device)\n",
    "y = torch.FloatTensor(Y_train.values).to(device)\n",
    "# construct TensorDataset\n",
    "b_data = TensorDataset(B_feature, y)\n",
    "trainDataLoader2 = DataLoader(dataset=b_data, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -3.9883, -14.4684,  11.4137,  ...,  -9.2443,   3.9696,  12.5899],\n",
       "         [-11.7305,  -0.8635,  -1.0897,  ...,  15.4855,  -6.0635, -34.4936],\n",
       "         [  1.5929,  25.8298,  -7.9542,  ...,  18.5808,  -1.4676,  14.9383],\n",
       "         ...,\n",
       "         [ -3.0039, -12.8343,  -1.4590,  ...,   0.4499,  -0.4883,  14.8022],\n",
       "         [ 11.4158,   3.0018,  14.8687,  ...,  -3.6770,  -7.1107,   7.3389],\n",
       "         [-22.3551,  -0.0588,  -8.4288,  ...,   8.4430,  -1.0664, -12.4539]],\n",
       "        device='cuda:0'),\n",
       " tensor([4.1360e-03, 2.4651e-01, 1.0000e+00, 1.6831e-01, 2.4553e-01, 4.5574e-02,\n",
       "         5.6766e-01, 6.5160e-03, 5.1101e-02, 1.0000e+00, 1.0000e+00, 1.3382e-01,\n",
       "         8.5730e-03, 2.0783e-02, 7.1891e-02, 2.6463e-02, 2.0267e-01, 1.6792e-01,\n",
       "         2.2742e-01, 5.1173e-01, 5.5870e-02, 9.3305e-02, 3.9400e-03, 9.9018e-02,\n",
       "         1.0000e+00, 7.3892e-02, 1.1134e-02, 8.2544e-02, 1.1754e-02, 1.4302e-01,\n",
       "         1.0000e+00, 1.0000e+00, 2.4001e-02, 3.9460e-03, 7.5210e-03, 4.9375e-01,\n",
       "         7.5744e-02, 1.0000e+00, 3.5260e-03, 5.8990e-03, 2.1700e-03, 4.5005e-01,\n",
       "         4.2510e-02, 1.7691e-02, 5.5246e-01, 5.4247e-01, 4.0037e-02, 7.2380e-03,\n",
       "         1.0000e+00, 1.0000e+00, 9.4933e-02, 1.0215e-01, 2.7513e-02, 5.0409e-01,\n",
       "         4.4406e-02, 3.4820e-03, 2.5150e-03, 7.5520e-02, 1.6606e-01, 1.7035e-02,\n",
       "         1.0000e+00, 2.0123e-01, 4.6859e-01, 1.5479e-02, 4.6974e-02, 7.6769e-02,\n",
       "         1.0000e+00, 7.5300e-03, 4.4562e-02, 5.9721e-01, 1.0000e+00, 1.0000e+00,\n",
       "         2.4920e-03, 1.4490e-02, 2.7184e-01, 1.0000e+00, 5.9909e-02, 4.9775e-02,\n",
       "         4.7430e-02, 4.8986e-02, 1.3822e-02, 7.3280e-03, 7.6150e-03, 1.6374e-02,\n",
       "         3.6500e-03, 1.1365e-01, 5.3317e-02, 1.4296e-01, 2.6837e-01, 2.0740e-03,\n",
       "         8.5649e-02, 8.9796e-02, 1.9761e-01, 1.0000e+00, 4.7980e-01, 6.1790e-02,\n",
       "         1.0000e+00, 3.1884e-02, 1.5052e-01, 6.0920e-03, 8.0590e-03, 1.2072e-01,\n",
       "         1.8862e-02, 4.7769e-02, 1.0000e+00, 1.0344e-01, 1.1329e-02, 4.0965e-02,\n",
       "         1.1603e-02, 7.8006e-02, 1.0000e+00, 4.2997e-01, 1.0000e+00, 1.0000e+00,\n",
       "         5.1436e-01, 1.8354e-02, 2.4070e-03, 4.2662e-01, 1.0000e+00, 6.0750e-03,\n",
       "         2.8277e-01, 1.0000e+00, 9.5793e-02, 1.3929e-01, 3.8586e-02, 4.0534e-02,\n",
       "         7.1050e-03, 1.3639e-01, 3.9180e-03, 7.3580e-03, 6.2922e-02, 3.6223e-01,\n",
       "         2.2240e-03, 4.8136e-01, 1.1493e-01, 1.0000e+00, 2.6837e-01, 1.0685e-02,\n",
       "         7.3399e-02, 9.6187e-02, 6.0854e-02, 6.2861e-01, 1.0000e+00, 4.1211e-02,\n",
       "         1.9118e-02, 1.7843e-02, 2.6835e-01, 7.1250e-03, 5.2402e-01, 1.2015e-02,\n",
       "         3.9800e-03, 1.5176e-01, 1.0000e+00, 1.0000e+00, 6.2100e-03, 1.7691e-02,\n",
       "         7.2998e-02, 2.7960e-02, 1.0099e-01, 7.1799e-02, 5.8499e-01, 1.0000e+00,\n",
       "         1.6083e-02, 2.0276e-02, 1.0000e+00, 5.6947e-01, 9.1870e-03, 1.2860e-02,\n",
       "         1.3392e-01, 1.7724e-01, 4.0801e-02, 1.1230e-02, 3.4680e-03, 1.2598e-01,\n",
       "         1.0567e-02, 2.0684e-01, 4.2260e-03, 1.7095e-01, 7.4439e-01, 2.9810e-02,\n",
       "         3.9568e-02, 1.7075e-02, 1.0000e+00, 4.0180e-03, 1.7704e-01, 4.6100e-01,\n",
       "         1.0295e-02, 6.3530e-03, 1.2682e-01, 2.8672e-01, 3.5570e-03, 6.9900e-03,\n",
       "         3.3726e-01, 1.8584e-01, 7.3496e-01, 1.0151e-02, 5.6579e-02, 3.5980e-03,\n",
       "         1.4192e-02, 1.0000e+00, 1.8666e-02, 5.7270e-01, 1.1845e-02, 2.1529e-02,\n",
       "         1.6763e-02, 3.6273e-02, 2.0910e-01, 4.0965e-02, 1.5324e-02, 1.1073e-02,\n",
       "         2.5885e-02, 7.3712e-02, 3.9738e-02, 1.0000e+00, 2.8982e-02, 2.2268e-02,\n",
       "         2.8491e-01, 1.0000e+00, 1.0000e+00, 3.8577e-01, 6.4855e-02, 4.6099e-02,\n",
       "         2.6722e-02, 4.1774e-01, 9.9120e-02, 1.0000e+00, 1.0000e+00, 5.4247e-01,\n",
       "         3.7970e-03, 2.0103e-02, 1.0201e-01, 8.3027e-02, 1.2024e-02, 8.1978e-02,\n",
       "         6.5470e-03, 9.6010e-03, 9.1870e-03, 3.4680e-03, 2.6867e-02, 1.0000e+00,\n",
       "         5.8499e-01, 4.6462e-02, 8.8396e-02, 6.1810e-03, 3.7970e-03, 9.0022e-02,\n",
       "         2.3646e-01, 4.5574e-02, 1.1474e-01, 3.0548e-01, 2.8643e-02, 9.0022e-02,\n",
       "         1.2547e-02, 1.0000e+00, 1.5606e-01, 1.0000e+00, 1.4565e-02, 1.0000e+00,\n",
       "         1.9761e-01, 1.0431e-01, 5.7450e-03, 1.6606e-01, 7.5210e-03, 7.3180e-03,\n",
       "         9.3872e-02, 1.0000e+00, 9.3457e-02, 7.8172e-02, 3.4588e-02, 2.4827e-02,\n",
       "         9.0144e-02, 1.0000e+00, 1.0260e-01, 1.0000e+00, 1.0000e+00, 3.1188e-01,\n",
       "         6.3400e-02, 2.0705e-02, 5.1284e-02, 1.0000e+00, 1.0000e+00, 1.2137e-01,\n",
       "         1.2258e-02, 2.0152e-02, 2.4380e-03, 4.0519e-02, 4.4087e-01, 1.0000e+00,\n",
       "         1.7280e-02, 3.5970e-03, 2.3351e-01, 2.7566e-01, 2.5222e-01, 2.2885e-02,\n",
       "         7.9216e-02, 3.4490e-03, 8.0398e-02, 1.0000e+00, 1.9229e-02, 4.4771e-02,\n",
       "         1.0000e+00, 8.6790e-03, 1.2422e-01, 3.1968e-02, 1.5854e-02, 4.4974e-02,\n",
       "         7.0230e-03, 7.1450e-03, 4.9113e-02, 7.2500e-03, 7.1847e-02, 1.0000e+00,\n",
       "         1.1984e-02, 2.2480e-03, 1.0837e-02, 1.1248e-02, 3.9620e-03, 9.2490e-03,\n",
       "         2.1498e-02, 1.0786e-01, 7.5440e-03, 1.5606e-01, 3.5870e-03, 4.1294e-02,\n",
       "         4.2420e-03, 2.4890e-03, 8.6703e-02, 1.3937e-02, 1.1332e-02, 6.5596e-02,\n",
       "         9.8575e-02, 7.1538e-02, 8.2800e-03, 1.5761e-02, 4.5255e-02, 4.9794e-02,\n",
       "         1.0000e+00, 3.6630e-03, 7.2630e-03, 4.6524e-02, 1.0347e-01, 5.7534e-01,\n",
       "         4.3650e-03, 6.1105e-02, 9.9046e-02, 9.6600e-04, 8.5017e-02, 3.3817e-02,\n",
       "         3.0596e-02, 1.9157e-02, 5.2182e-02, 1.8440e-02, 1.1197e-01, 2.4110e-03,\n",
       "         3.8210e-03, 1.0769e-02, 4.1879e-02, 2.9981e-02, 4.5659e-01, 3.4450e-03,\n",
       "         1.5985e-01, 6.1810e-03, 7.1950e-02, 1.4121e-01, 1.0000e+00, 1.9090e-01,\n",
       "         3.9970e-03, 1.8909e-02, 4.9187e-02, 6.3839e-01, 8.6341e-02, 1.4763e-01,\n",
       "         1.1845e-02, 4.5873e-02, 3.9738e-02, 3.1613e-01, 5.4326e-01, 1.0374e-01,\n",
       "         1.4946e-01, 7.5990e-03, 1.0000e+00, 4.1743e-01, 4.7707e-01, 9.9046e-02,\n",
       "         1.0474e-01, 5.1700e-01, 4.8282e-01, 9.7090e-03, 2.2595e-02, 6.6200e-03,\n",
       "         1.2941e-01, 7.5238e-02, 4.8525e-02, 6.2990e-03, 3.6899e-01, 2.1421e-01,\n",
       "         1.1141e-02, 4.1410e-03, 3.5279e-02, 1.0000e+00, 5.7838e-02, 2.1789e-01,\n",
       "         1.2757e-02, 3.9074e-01, 9.9096e-02, 9.7397e-02, 2.4125e-01, 4.6399e-01,\n",
       "         8.0957e-02, 2.2280e-03, 7.4320e-03, 1.0479e-02, 4.8305e-02, 1.0000e+00,\n",
       "         1.2771e-01, 2.7513e-02, 1.0000e+00, 1.1959e-01, 6.0470e-03, 2.5260e-03,\n",
       "         1.0000e+00, 3.9300e-03, 3.8040e-03, 2.6722e-02, 1.2137e-01, 1.3921e-02,\n",
       "         6.4770e-03, 4.5140e-01, 1.3912e-01, 6.4394e-02, 2.4589e-01, 1.2525e-01,\n",
       "         1.7947e-01, 5.3607e-02, 6.8440e-03, 9.7085e-02, 1.4912e-02, 4.2007e-01,\n",
       "         6.5087e-02, 3.0198e-02, 3.9970e-03, 1.0000e+00, 2.2065e-01, 5.1430e-01,\n",
       "         6.2861e-01, 8.9943e-02, 5.2588e-01, 5.7831e-02, 1.0000e+00, 1.1344e-02,\n",
       "         1.0000e+00, 1.8901e-02, 2.7444e-02, 3.7670e-03, 2.5510e-03, 6.5160e-03,\n",
       "         1.0000e+00, 4.7603e-01, 5.7831e-02, 9.8575e-02, 1.0000e+00, 7.8092e-02,\n",
       "         1.0000e+00, 3.3800e-03, 1.0000e+00, 1.8317e-01, 3.9190e-03, 1.6076e-02,\n",
       "         9.1498e-02, 1.3260e-02, 2.1334e-01, 3.6880e-03, 2.5883e-01, 3.9220e-03,\n",
       "         2.2480e-03, 5.9336e-02, 3.9220e-03, 1.2508e-01, 5.8277e-02, 1.3717e-02,\n",
       "         2.1750e-03, 1.0000e+00, 3.9015e-01, 2.2001e-02, 2.4765e-01, 3.1036e-01,\n",
       "         4.6501e-01, 3.4889e-01, 5.7660e-03, 7.7200e-03, 1.0000e+00, 1.1659e-01,\n",
       "         2.8010e-01, 7.8877e-02, 4.6616e-01, 3.3154e-02, 7.7200e-03, 1.1529e-02,\n",
       "         9.7847e-02, 2.0045e-02, 2.2873e-01, 1.0000e+00, 2.0152e-02, 1.8153e-01,\n",
       "         2.6386e-02, 3.4249e-01, 4.4250e-03, 2.3573e-01, 2.9182e-01, 6.4800e-03,\n",
       "         3.5870e-03, 2.6101e-02, 3.5870e-03, 1.0000e+00, 1.0345e-02, 4.9046e-02,\n",
       "         1.7035e-01, 4.7883e-02, 3.7592e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.8539e-02, 2.2662e-02, 1.0000e+00, 7.1191e-01, 6.5087e-02, 1.0308e-01,\n",
       "         5.8820e-03, 1.0519e-02, 6.4100e-03, 4.4562e-02, 1.0000e+00, 1.2643e-02,\n",
       "         6.3476e-02, 6.0884e-02, 3.3719e-02, 4.0626e-02, 1.2004e-01, 1.0000e+00,\n",
       "         1.0000e+00, 3.4154e-02, 3.4570e-03, 4.1840e-03, 3.6779e-02, 1.3040e-02,\n",
       "         4.9330e-02, 3.7603e-02, 7.2620e-03, 1.0000e+00, 8.8731e-02, 7.4576e-02,\n",
       "         5.1327e-01, 3.5491e-01, 6.0944e-02, 4.9385e-02, 3.3512e-02, 1.0000e+00,\n",
       "         3.9480e-03, 6.5702e-02, 5.1448e-02, 4.6671e-01, 7.2510e-03, 2.0152e-02,\n",
       "         1.4463e-02, 1.0000e+00, 1.1767e-01, 2.0549e-01, 8.6759e-02, 1.6022e-01,\n",
       "         1.0000e+00, 1.0000e+00, 2.1553e-01, 1.3718e-02, 1.0734e-02, 1.0793e-01,\n",
       "         1.0062e-02, 1.0949e-02, 3.8660e-03, 1.0000e+00, 4.5081e-02, 1.2531e-02,\n",
       "         6.1790e-02, 4.2260e-03, 1.1406e-01, 2.2976e-02, 5.5780e-02, 2.8681e-01,\n",
       "         2.6613e-02, 1.4192e-02, 5.6766e-01, 1.0000e+00, 1.2508e-01, 4.8510e-03,\n",
       "         5.7534e-01, 1.0000e+00, 1.8148e-02, 4.7990e-03, 3.7388e-02, 1.3924e-02,\n",
       "         3.6710e-03, 1.0000e+00, 3.0505e-02, 3.2302e-01, 6.4309e-02, 2.6341e-01,\n",
       "         3.2239e-01, 7.3530e-03, 2.7659e-01, 1.2874e-02, 2.4000e-03, 1.5649e-02,\n",
       "         1.0581e-01, 7.4189e-02, 1.3289e-02, 1.0000e+00, 1.2385e-02, 8.1295e-02,\n",
       "         1.2757e-02, 8.3623e-02, 1.1657e-02, 7.1864e-02, 7.3940e-03, 7.5134e-02,\n",
       "         1.0000e+00, 1.0000e+00, 3.2663e-02, 6.1450e-03, 7.6035e-02, 3.9060e-03,\n",
       "         4.0241e-02], device='cuda:0'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_data.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1f0c56d4cd0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_dnn_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization DNN model\n",
    "\n",
    "predictor = DNN(dim_dnn_in, dim_dnn_out).to(device)\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=1e-3,betas=(0.9,0.99))\n",
    "#loss1-softmax\n",
    "loss_func = nn.MSELoss().to(device)\n",
    "#loss2-sigmoid\n",
    "#loss_func = nn.BCELoss().to(device)\n",
    "#loss3-sigmoid\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "#criterion = torch.nn.MSELoss(size_average=True)\n",
    "#criterion = torch.nn.BCELoss(size_average=True) # Defined loss function\n",
    "#optimizer = optim.Adm(model.parameters(), lr=0.01) # Defined optimizer\n",
    "loss_train = np.zeros((epochs, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch: 0001, Training loss=0.14073600\n",
      "Epoch:  1\n",
      "Epoch: 0002, Training loss=0.14142042\n",
      "Epoch:  2\n",
      "Epoch: 0003, Training loss=0.14093786\n",
      "Epoch:  3\n",
      "Epoch: 0004, Training loss=0.13917321\n",
      "Epoch:  4\n",
      "Epoch: 0005, Training loss=0.13617325\n",
      "Epoch:  5\n",
      "Epoch: 0006, Training loss=0.14401031\n",
      "Epoch:  6\n",
      "Epoch: 0007, Training loss=0.13115421\n",
      "Epoch:  7\n",
      "Epoch: 0008, Training loss=0.12830086\n",
      "Epoch:  8\n",
      "Epoch: 0009, Training loss=0.11829123\n",
      "Epoch:  9\n",
      "Epoch: 0010, Training loss=0.11946681\n",
      "Epoch:  10\n",
      "Epoch: 0011, Training loss=0.11076292\n",
      "Epoch:  11\n",
      "Epoch: 0012, Training loss=0.10806186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  12\n",
      "Epoch: 0013, Training loss=0.10718475\n",
      "Epoch:  13\n",
      "Epoch: 0014, Training loss=0.10543577\n",
      "Epoch:  14\n",
      "Epoch: 0015, Training loss=0.10517173\n",
      "Epoch:  15\n",
      "Epoch: 0016, Training loss=0.10508906\n",
      "Epoch:  16\n",
      "Epoch: 0017, Training loss=0.10479159\n",
      "Epoch:  17\n",
      "Epoch: 0018, Training loss=0.10460429\n",
      "Epoch:  18\n",
      "Epoch: 0019, Training loss=0.10460255\n",
      "Epoch:  19\n",
      "Epoch: 0020, Training loss=0.10449547\n",
      "Epoch:  20\n",
      "Epoch: 0021, Training loss=0.10445882\n",
      "Epoch:  21\n",
      "Epoch: 0022, Training loss=0.10449649\n",
      "Epoch:  22\n",
      "Epoch: 0023, Training loss=0.10448916\n",
      "Epoch:  23\n",
      "Epoch: 0024, Training loss=0.10443692\n",
      "Epoch:  24\n",
      "Epoch: 0025, Training loss=0.10450164\n",
      "Epoch:  25\n",
      "Epoch: 0026, Training loss=0.10444888\n",
      "Epoch:  26\n",
      "Epoch: 0027, Training loss=0.10447725\n",
      "Epoch:  27\n",
      "Epoch: 0028, Training loss=0.10443346\n",
      "Epoch:  28\n",
      "Epoch: 0029, Training loss=0.10448634\n",
      "Epoch:  29\n",
      "Epoch: 0030, Training loss=0.10442650\n",
      "Epoch:  30\n",
      "Epoch: 0031, Training loss=0.10449669\n",
      "Epoch:  31\n",
      "Epoch: 0032, Training loss=0.10444964\n",
      "Epoch:  32\n",
      "Epoch: 0033, Training loss=0.10453949\n",
      "Epoch:  33\n",
      "Epoch: 0034, Training loss=0.10459840\n",
      "Epoch:  34\n",
      "Epoch: 0035, Training loss=0.10464399\n",
      "Epoch:  35\n",
      "Epoch: 0036, Training loss=0.10484861\n",
      "Epoch:  36\n",
      "Epoch: 0037, Training loss=0.10463048\n",
      "Epoch:  37\n",
      "Epoch: 0038, Training loss=0.10514608\n",
      "Epoch:  38\n",
      "Epoch: 0039, Training loss=0.10516437\n",
      "Epoch:  39\n",
      "Epoch: 0040, Training loss=0.10456661\n",
      "Epoch:  40\n",
      "Epoch: 0041, Training loss=0.10468955\n",
      "Epoch:  41\n",
      "Epoch: 0042, Training loss=0.10472675\n",
      "Epoch:  42\n",
      "Epoch: 0043, Training loss=0.10451252\n",
      "Epoch:  43\n",
      "Epoch: 0044, Training loss=0.10450704\n",
      "Epoch:  44\n",
      "Epoch: 0045, Training loss=0.10468613\n",
      "Epoch:  45\n",
      "Epoch: 0046, Training loss=0.10451965\n",
      "Epoch:  46\n",
      "Epoch: 0047, Training loss=0.10445361\n",
      "Epoch:  47\n",
      "Epoch: 0048, Training loss=0.10462721\n",
      "Epoch:  48\n",
      "Epoch: 0049, Training loss=0.10449853\n",
      "Epoch:  49\n",
      "Epoch: 0050, Training loss=0.10444918\n",
      "Epoch:  50\n",
      "Epoch: 0051, Training loss=0.10457293\n",
      "Epoch:  51\n",
      "Epoch: 0052, Training loss=0.10449439\n",
      "Epoch:  52\n",
      "Epoch: 0053, Training loss=0.10447221\n",
      "Epoch:  53\n",
      "Epoch: 0054, Training loss=0.10457513\n",
      "Epoch:  54\n",
      "Epoch: 0055, Training loss=0.10446036\n",
      "Epoch:  55\n",
      "Epoch: 0056, Training loss=0.10452617\n",
      "Epoch:  56\n",
      "Epoch: 0057, Training loss=0.10454286\n",
      "Epoch:  57\n",
      "Epoch: 0058, Training loss=0.10445792\n",
      "Epoch:  58\n",
      "Epoch: 0059, Training loss=0.10456757\n",
      "Epoch:  59\n",
      "Epoch: 0060, Training loss=0.10446105\n",
      "Epoch:  60\n",
      "Epoch: 0061, Training loss=0.10454343\n",
      "Epoch:  61\n",
      "Epoch: 0062, Training loss=0.10448057\n",
      "Epoch:  62\n",
      "Epoch: 0063, Training loss=0.10454783\n",
      "Epoch:  63\n",
      "Epoch: 0064, Training loss=0.10457036\n",
      "Epoch:  64\n",
      "Epoch: 0065, Training loss=0.10454462\n",
      "Epoch:  65\n",
      "Epoch: 0066, Training loss=0.10468506\n",
      "Epoch:  66\n",
      "Epoch: 0067, Training loss=0.10454364\n",
      "Epoch:  67\n",
      "Epoch: 0068, Training loss=0.10496920\n",
      "Epoch:  68\n",
      "Epoch: 0069, Training loss=0.10452149\n",
      "Epoch:  69\n",
      "Epoch: 0070, Training loss=0.10511844\n",
      "Epoch:  70\n",
      "Epoch: 0071, Training loss=0.10489989\n",
      "Epoch:  71\n",
      "Epoch: 0072, Training loss=0.10462634\n",
      "Epoch:  72\n",
      "Epoch: 0073, Training loss=0.10486861\n",
      "Epoch:  73\n",
      "Epoch: 0074, Training loss=0.10462864\n",
      "Epoch:  74\n",
      "Epoch: 0075, Training loss=0.10451341\n",
      "Epoch:  75\n",
      "Epoch: 0076, Training loss=0.10460807\n",
      "Epoch:  76\n",
      "Epoch: 0077, Training loss=0.10460985\n",
      "Epoch:  77\n",
      "Epoch: 0078, Training loss=0.10445046\n",
      "Epoch:  78\n",
      "Epoch: 0079, Training loss=0.10456513\n",
      "Epoch:  79\n",
      "Epoch: 0080, Training loss=0.10456306\n",
      "Epoch:  80\n",
      "Epoch: 0081, Training loss=0.10445239\n",
      "Epoch:  81\n",
      "Epoch: 0082, Training loss=0.10455810\n",
      "Epoch:  82\n",
      "Epoch: 0083, Training loss=0.10452271\n",
      "Epoch:  83\n",
      "Epoch: 0084, Training loss=0.10446464\n",
      "Epoch:  84\n",
      "Epoch: 0085, Training loss=0.10458032\n",
      "Epoch:  85\n",
      "Epoch: 0086, Training loss=0.10445310\n",
      "Epoch:  86\n",
      "Epoch: 0087, Training loss=0.10457854\n",
      "Epoch:  87\n",
      "Epoch: 0088, Training loss=0.10450590\n",
      "Epoch:  88\n",
      "Epoch: 0089, Training loss=0.10456323\n",
      "Epoch:  89\n",
      "Epoch: 0090, Training loss=0.10472082\n",
      "Epoch:  90\n",
      "Epoch: 0091, Training loss=0.10450519\n",
      "Epoch:  91\n",
      "Epoch: 0092, Training loss=0.10504012\n",
      "Epoch:  92\n",
      "Epoch: 0093, Training loss=0.10459048\n",
      "Epoch:  93\n",
      "Epoch: 0094, Training loss=0.10495897\n",
      "Epoch:  94\n",
      "Epoch: 0095, Training loss=0.10497520\n",
      "Epoch:  95\n",
      "Epoch: 0096, Training loss=0.10453309\n",
      "Epoch:  96\n",
      "Epoch: 0097, Training loss=0.10490678\n",
      "Epoch:  97\n",
      "Epoch: 0098, Training loss=0.10474507\n",
      "Epoch:  98\n",
      "Epoch: 0099, Training loss=0.10450397\n",
      "Epoch:  99\n",
      "Epoch: 0100, Training loss=0.10452528\n",
      "Epoch:  100\n",
      "Epoch: 0101, Training loss=0.10468596\n",
      "Epoch:  101\n",
      "Epoch: 0102, Training loss=0.10458422\n",
      "Epoch:  102\n",
      "Epoch: 0103, Training loss=0.10445671\n",
      "Epoch:  103\n",
      "Epoch: 0104, Training loss=0.10458647\n",
      "Epoch:  104\n",
      "Epoch: 0105, Training loss=0.10460596\n",
      "Epoch:  105\n",
      "Epoch: 0106, Training loss=0.10445218\n",
      "Epoch:  106\n",
      "Epoch: 0107, Training loss=0.10450915\n",
      "Epoch:  107\n",
      "Epoch: 0108, Training loss=0.10454644\n",
      "Epoch:  108\n",
      "Epoch: 0109, Training loss=0.10445298\n",
      "Epoch:  109\n",
      "Epoch: 0110, Training loss=0.10447486\n",
      "Epoch:  110\n",
      "Epoch: 0111, Training loss=0.10452492\n",
      "Epoch:  111\n",
      "Epoch: 0112, Training loss=0.10443813\n",
      "Epoch:  112\n",
      "Epoch: 0113, Training loss=0.10448463\n",
      "Epoch:  113\n",
      "Epoch: 0114, Training loss=0.10451345\n",
      "Epoch:  114\n",
      "Epoch: 0115, Training loss=0.10443315\n",
      "Epoch:  115\n",
      "Epoch: 0116, Training loss=0.10458552\n",
      "Epoch:  116\n",
      "Epoch: 0117, Training loss=0.10449313\n",
      "Epoch:  117\n",
      "Epoch: 0118, Training loss=0.10464080\n",
      "Epoch:  118\n",
      "Epoch: 0119, Training loss=0.10477176\n",
      "Epoch:  119\n",
      "Epoch: 0120, Training loss=0.10459843\n",
      "Epoch:  120\n",
      "Epoch: 0121, Training loss=0.10542470\n",
      "Epoch:  121\n",
      "Epoch: 0122, Training loss=0.10470948\n",
      "Epoch:  122\n",
      "Epoch: 0123, Training loss=0.10490049\n",
      "Epoch:  123\n",
      "Epoch: 0124, Training loss=0.10518337\n",
      "Epoch:  124\n",
      "Epoch: 0125, Training loss=0.10466237\n",
      "Epoch:  125\n",
      "Epoch: 0126, Training loss=0.10451993\n",
      "Epoch:  126\n",
      "Epoch: 0127, Training loss=0.10447484\n",
      "Epoch:  127\n",
      "Epoch: 0128, Training loss=0.10465756\n",
      "Epoch:  128\n",
      "Epoch: 0129, Training loss=0.10469390\n",
      "Epoch:  129\n",
      "Epoch: 0130, Training loss=0.10445843\n",
      "Epoch:  130\n",
      "Epoch: 0131, Training loss=0.10445038\n",
      "Epoch:  131\n",
      "Epoch: 0132, Training loss=0.10451171\n",
      "Epoch:  132\n",
      "Epoch: 0133, Training loss=0.10452756\n",
      "Epoch:  133\n",
      "Epoch: 0134, Training loss=0.10446136\n",
      "Epoch:  134\n",
      "Epoch: 0135, Training loss=0.10443392\n",
      "Epoch:  135\n",
      "Epoch: 0136, Training loss=0.10449534\n",
      "Epoch:  136\n",
      "Epoch: 0137, Training loss=0.10449034\n",
      "Epoch:  137\n",
      "Epoch: 0138, Training loss=0.10443415\n",
      "Epoch:  138\n",
      "Epoch: 0139, Training loss=0.10446897\n",
      "Epoch:  139\n",
      "Epoch: 0140, Training loss=0.10448141\n",
      "Epoch:  140\n",
      "Epoch: 0141, Training loss=0.10443287\n",
      "Epoch:  141\n",
      "Epoch: 0142, Training loss=0.10448536\n",
      "Epoch:  142\n",
      "Epoch: 0143, Training loss=0.10447855\n",
      "Epoch:  143\n",
      "Epoch: 0144, Training loss=0.10444719\n",
      "Epoch:  144\n",
      "Epoch: 0145, Training loss=0.10460648\n",
      "Epoch:  145\n",
      "Epoch: 0146, Training loss=0.10446897\n",
      "Epoch:  146\n",
      "Epoch: 0147, Training loss=0.10476326\n",
      "Epoch:  147\n",
      "Epoch: 0148, Training loss=0.10485128\n",
      "Epoch:  148\n",
      "Epoch: 0149, Training loss=0.10460791\n",
      "Epoch:  149\n",
      "Epoch: 0150, Training loss=0.10571358\n",
      "Epoch:  150\n",
      "Epoch: 0151, Training loss=0.10484019\n",
      "Epoch:  151\n",
      "Epoch: 0152, Training loss=0.10464661\n",
      "Epoch:  152\n",
      "Epoch: 0153, Training loss=0.10483379\n",
      "Epoch:  153\n",
      "Epoch: 0154, Training loss=0.10492735\n",
      "Epoch:  154\n",
      "Epoch: 0155, Training loss=0.10475631\n",
      "Epoch:  155\n",
      "Epoch: 0156, Training loss=0.10447298\n",
      "Epoch:  156\n",
      "Epoch: 0157, Training loss=0.10462597\n",
      "Epoch:  157\n",
      "Epoch: 0158, Training loss=0.10475744\n",
      "Epoch:  158\n",
      "Epoch: 0159, Training loss=0.10460394\n",
      "Epoch:  159\n",
      "Epoch: 0160, Training loss=0.10445932\n",
      "Epoch:  160\n",
      "Epoch: 0161, Training loss=0.10445987\n",
      "Epoch:  161\n",
      "Epoch: 0162, Training loss=0.10452330\n",
      "Epoch:  162\n",
      "Epoch: 0163, Training loss=0.10450709\n",
      "Epoch:  163\n",
      "Epoch: 0164, Training loss=0.10443486\n",
      "Epoch:  164\n",
      "Epoch: 0165, Training loss=0.10443744\n",
      "Epoch:  165\n",
      "Epoch: 0166, Training loss=0.10449206\n",
      "Epoch:  166\n",
      "Epoch: 0167, Training loss=0.10446206\n",
      "Epoch:  167\n",
      "Epoch: 0168, Training loss=0.10442597\n",
      "Epoch:  168\n",
      "Epoch: 0169, Training loss=0.10446603\n",
      "Epoch:  169\n",
      "Epoch: 0170, Training loss=0.10448569\n",
      "Epoch:  170\n",
      "Epoch: 0171, Training loss=0.10443008\n",
      "Epoch:  171\n",
      "Epoch: 0172, Training loss=0.10449639\n",
      "Epoch:  172\n",
      "Epoch: 0173, Training loss=0.10451423\n",
      "Epoch:  173\n",
      "Epoch: 0174, Training loss=0.10443801\n",
      "Epoch:  174\n",
      "Epoch: 0175, Training loss=0.10461438\n",
      "Epoch:  175\n",
      "Epoch: 0176, Training loss=0.10453308\n",
      "Epoch:  176\n",
      "Epoch: 0177, Training loss=0.10452451\n",
      "Epoch:  177\n",
      "Epoch: 0178, Training loss=0.10486769\n",
      "Epoch:  178\n",
      "Epoch: 0179, Training loss=0.10448834\n",
      "Epoch:  179\n",
      "Epoch: 0180, Training loss=0.10477477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  180\n",
      "Epoch: 0181, Training loss=0.10494240\n",
      "Epoch:  181\n",
      "Epoch: 0182, Training loss=0.10447871\n",
      "Epoch:  182\n",
      "Epoch: 0183, Training loss=0.10471171\n",
      "Epoch:  183\n",
      "Epoch: 0184, Training loss=0.10476775\n",
      "Epoch:  184\n",
      "Epoch: 0185, Training loss=0.10451405\n",
      "Epoch:  185\n",
      "Epoch: 0186, Training loss=0.10450434\n",
      "Epoch:  186\n",
      "Epoch: 0187, Training loss=0.10463460\n",
      "Epoch:  187\n",
      "Epoch: 0188, Training loss=0.10465564\n",
      "Epoch:  188\n",
      "Epoch: 0189, Training loss=0.10450678\n",
      "Epoch:  189\n",
      "Epoch: 0190, Training loss=0.10456882\n",
      "Epoch:  190\n",
      "Epoch: 0191, Training loss=0.10479669\n",
      "Epoch:  191\n",
      "Epoch: 0192, Training loss=0.10459951\n",
      "Epoch:  192\n",
      "Epoch: 0193, Training loss=0.10450009\n",
      "Epoch:  193\n",
      "Epoch: 0194, Training loss=0.10478222\n",
      "Epoch:  194\n",
      "Epoch: 0195, Training loss=0.10467076\n",
      "Epoch:  195\n",
      "Epoch: 0196, Training loss=0.10445446\n",
      "Epoch:  196\n",
      "Epoch: 0197, Training loss=0.10460965\n",
      "Epoch:  197\n",
      "Epoch: 0198, Training loss=0.10465343\n",
      "Epoch:  198\n",
      "Epoch: 0199, Training loss=0.10448022\n",
      "Epoch:  199\n",
      "Epoch: 0200, Training loss=0.10446742\n",
      "Epoch:  200\n",
      "Epoch: 0201, Training loss=0.10457794\n",
      "Epoch:  201\n",
      "Epoch: 0202, Training loss=0.10454977\n",
      "Epoch:  202\n",
      "Epoch: 0203, Training loss=0.10444259\n",
      "Epoch:  203\n",
      "Epoch: 0204, Training loss=0.10455298\n",
      "Epoch:  204\n",
      "Epoch: 0205, Training loss=0.10461646\n",
      "Epoch:  205\n",
      "Epoch: 0206, Training loss=0.10447028\n",
      "Epoch:  206\n",
      "Epoch: 0207, Training loss=0.10455901\n",
      "Epoch:  207\n",
      "Epoch: 0208, Training loss=0.10470229\n",
      "Epoch:  208\n",
      "Epoch: 0209, Training loss=0.10449816\n",
      "Epoch:  209\n",
      "Epoch: 0210, Training loss=0.10458044\n",
      "Epoch:  210\n",
      "Epoch: 0211, Training loss=0.10475779\n",
      "Epoch:  211\n",
      "Epoch: 0212, Training loss=0.10451063\n",
      "Epoch:  212\n",
      "Epoch: 0213, Training loss=0.10457107\n",
      "Epoch:  213\n",
      "Epoch: 0214, Training loss=0.10478520\n",
      "Epoch:  214\n",
      "Epoch: 0215, Training loss=0.10452327\n",
      "Epoch:  215\n",
      "Epoch: 0216, Training loss=0.10450037\n",
      "Epoch:  216\n",
      "Epoch: 0217, Training loss=0.10464977\n",
      "Epoch:  217\n",
      "Epoch: 0218, Training loss=0.10455950\n",
      "Epoch:  218\n",
      "Epoch: 0219, Training loss=0.10444745\n",
      "Epoch:  219\n",
      "Epoch: 0220, Training loss=0.10453708\n",
      "Epoch:  220\n",
      "Epoch: 0221, Training loss=0.10457068\n",
      "Epoch:  221\n",
      "Epoch: 0222, Training loss=0.10444662\n",
      "Epoch:  222\n",
      "Epoch: 0223, Training loss=0.10447834\n",
      "Epoch:  223\n",
      "Epoch: 0224, Training loss=0.10456609\n",
      "Epoch:  224\n",
      "Epoch: 0225, Training loss=0.10445766\n",
      "Epoch:  225\n",
      "Epoch: 0226, Training loss=0.10446426\n",
      "Epoch:  226\n",
      "Epoch: 0227, Training loss=0.10456642\n",
      "Epoch:  227\n",
      "Epoch: 0228, Training loss=0.10446676\n",
      "Epoch:  228\n",
      "Epoch: 0229, Training loss=0.10446987\n",
      "Epoch:  229\n",
      "Epoch: 0230, Training loss=0.10458297\n",
      "Epoch:  230\n",
      "Epoch: 0231, Training loss=0.10445498\n",
      "Epoch:  231\n",
      "Epoch: 0232, Training loss=0.10450879\n",
      "Epoch:  232\n",
      "Epoch: 0233, Training loss=0.10460471\n",
      "Epoch:  233\n",
      "Epoch: 0234, Training loss=0.10444003\n",
      "Epoch:  234\n",
      "Epoch: 0235, Training loss=0.10460021\n",
      "Epoch:  235\n",
      "Epoch: 0236, Training loss=0.10461710\n",
      "Epoch:  236\n",
      "Epoch: 0237, Training loss=0.10445584\n",
      "Epoch:  237\n",
      "Epoch: 0238, Training loss=0.10476793\n",
      "Epoch:  238\n",
      "Epoch: 0239, Training loss=0.10465913\n",
      "Epoch:  239\n",
      "Epoch: 0240, Training loss=0.10450795\n",
      "Epoch:  240\n",
      "Epoch: 0241, Training loss=0.10492894\n",
      "Epoch:  241\n",
      "Epoch: 0242, Training loss=0.10469330\n",
      "Epoch:  242\n",
      "Epoch: 0243, Training loss=0.10449284\n",
      "Epoch:  243\n",
      "Epoch: 0244, Training loss=0.10474157\n",
      "Epoch:  244\n",
      "Epoch: 0245, Training loss=0.10466148\n",
      "Epoch:  245\n",
      "Epoch: 0246, Training loss=0.10445727\n",
      "Epoch:  246\n",
      "Epoch: 0247, Training loss=0.10450812\n",
      "Epoch:  247\n",
      "Epoch: 0248, Training loss=0.10457641\n",
      "Epoch:  248\n",
      "Epoch: 0249, Training loss=0.10449783\n",
      "Epoch:  249\n",
      "Epoch: 0250, Training loss=0.10443973\n",
      "Epoch:  250\n",
      "Epoch: 0251, Training loss=0.10447368\n",
      "Epoch:  251\n",
      "Epoch: 0252, Training loss=0.10451325\n",
      "Epoch:  252\n",
      "Epoch: 0253, Training loss=0.10446394\n",
      "Epoch:  253\n",
      "Epoch: 0254, Training loss=0.10443375\n",
      "Epoch:  254\n",
      "Epoch: 0255, Training loss=0.10449612\n",
      "Epoch:  255\n",
      "Epoch: 0256, Training loss=0.10448556\n",
      "Epoch:  256\n",
      "Epoch: 0257, Training loss=0.10442316\n",
      "Epoch:  257\n",
      "Epoch: 0258, Training loss=0.10447367\n",
      "Epoch:  258\n",
      "Epoch: 0259, Training loss=0.10449095\n",
      "Epoch:  259\n",
      "Epoch: 0260, Training loss=0.10442049\n",
      "Epoch:  260\n",
      "Epoch: 0261, Training loss=0.10450178\n",
      "Epoch:  261\n",
      "Epoch: 0262, Training loss=0.10449383\n",
      "Epoch:  262\n",
      "Epoch: 0263, Training loss=0.10444256\n",
      "Epoch:  263\n",
      "Epoch: 0264, Training loss=0.10462534\n",
      "Epoch:  264\n",
      "Epoch: 0265, Training loss=0.10448087\n",
      "Epoch:  265\n",
      "Epoch: 0266, Training loss=0.10462140\n",
      "Epoch:  266\n",
      "Epoch: 0267, Training loss=0.10485845\n",
      "Epoch:  267\n",
      "Epoch: 0268, Training loss=0.10444346\n",
      "Epoch:  268\n",
      "Epoch: 0269, Training loss=0.10492741\n",
      "Epoch:  269\n",
      "Epoch: 0270, Training loss=0.10485262\n",
      "Epoch:  270\n",
      "Epoch: 0271, Training loss=0.10451285\n",
      "Epoch:  271\n",
      "Epoch: 0272, Training loss=0.10460135\n",
      "Epoch:  272\n",
      "Epoch: 0273, Training loss=0.10471074\n",
      "Epoch:  273\n",
      "Epoch: 0274, Training loss=0.10462198\n",
      "Epoch:  274\n",
      "Epoch: 0275, Training loss=0.10448953\n",
      "Epoch:  275\n",
      "Epoch: 0276, Training loss=0.10446525\n",
      "Epoch:  276\n",
      "Epoch: 0277, Training loss=0.10450105\n",
      "Epoch:  277\n",
      "Epoch: 0278, Training loss=0.10460904\n",
      "Epoch:  278\n",
      "Epoch: 0279, Training loss=0.10450913\n",
      "Epoch:  279\n",
      "Epoch: 0280, Training loss=0.10444237\n",
      "Epoch:  280\n",
      "Epoch: 0281, Training loss=0.10451093\n",
      "Epoch:  281\n",
      "Epoch: 0282, Training loss=0.10449497\n",
      "Epoch:  282\n",
      "Epoch: 0283, Training loss=0.10444367\n",
      "Epoch:  283\n",
      "Epoch: 0284, Training loss=0.10444239\n",
      "Epoch:  284\n",
      "Epoch: 0285, Training loss=0.10446305\n",
      "Epoch:  285\n",
      "Epoch: 0286, Training loss=0.10445025\n",
      "Epoch:  286\n",
      "Epoch: 0287, Training loss=0.10442567\n",
      "Epoch:  287\n",
      "Epoch: 0288, Training loss=0.10445770\n",
      "Epoch:  288\n",
      "Epoch: 0289, Training loss=0.10444759\n",
      "Epoch:  289\n",
      "Epoch: 0290, Training loss=0.10442676\n",
      "Epoch:  290\n",
      "Epoch: 0291, Training loss=0.10447128\n",
      "Epoch:  291\n",
      "Epoch: 0292, Training loss=0.10444333\n",
      "Epoch:  292\n",
      "Epoch: 0293, Training loss=0.10444487\n",
      "Epoch:  293\n",
      "Epoch: 0294, Training loss=0.10451560\n",
      "Epoch:  294\n",
      "Epoch: 0295, Training loss=0.10442974\n",
      "Epoch:  295\n",
      "Epoch: 0296, Training loss=0.10455172\n",
      "Epoch:  296\n",
      "Epoch: 0297, Training loss=0.10457357\n",
      "Epoch:  297\n",
      "Epoch: 0298, Training loss=0.10447324\n",
      "Epoch:  298\n",
      "Epoch: 0299, Training loss=0.10484029\n",
      "Epoch:  299\n",
      "Epoch: 0300, Training loss=0.10455099\n",
      "Epoch:  300\n",
      "Epoch: 0301, Training loss=0.10461868\n",
      "Epoch:  301\n",
      "Epoch: 0302, Training loss=0.10485580\n",
      "Epoch:  302\n",
      "Epoch: 0303, Training loss=0.10457297\n",
      "Epoch:  303\n",
      "Epoch: 0304, Training loss=0.10447284\n",
      "Epoch:  304\n",
      "Epoch: 0305, Training loss=0.10458127\n",
      "Epoch:  305\n",
      "Epoch: 0306, Training loss=0.10460304\n",
      "Epoch:  306\n",
      "Epoch: 0307, Training loss=0.10447550\n",
      "Epoch:  307\n",
      "Epoch: 0308, Training loss=0.10444139\n",
      "Epoch:  308\n",
      "Epoch: 0309, Training loss=0.10449687\n",
      "Epoch:  309\n",
      "Epoch: 0310, Training loss=0.10450739\n",
      "Epoch:  310\n",
      "Epoch: 0311, Training loss=0.10444610\n",
      "Epoch:  311\n",
      "Epoch: 0312, Training loss=0.10443448\n",
      "Epoch:  312\n",
      "Epoch: 0313, Training loss=0.10447405\n",
      "Epoch:  313\n",
      "Epoch: 0314, Training loss=0.10444973\n",
      "Epoch:  314\n",
      "Epoch: 0315, Training loss=0.10442118\n",
      "Epoch:  315\n",
      "Epoch: 0316, Training loss=0.10445128\n",
      "Epoch:  316\n",
      "Epoch: 0317, Training loss=0.10444356\n",
      "Epoch:  317\n",
      "Epoch: 0318, Training loss=0.10442080\n",
      "Epoch:  318\n",
      "Epoch: 0319, Training loss=0.10445174\n",
      "Epoch:  319\n",
      "Epoch: 0320, Training loss=0.10443742\n",
      "Epoch:  320\n",
      "Epoch: 0321, Training loss=0.10442922\n",
      "Epoch:  321\n",
      "Epoch: 0322, Training loss=0.10448038\n",
      "Epoch:  322\n",
      "Epoch: 0323, Training loss=0.10442549\n",
      "Epoch:  323\n",
      "Epoch: 0324, Training loss=0.10450679\n",
      "Epoch:  324\n",
      "Epoch: 0325, Training loss=0.10452356\n",
      "Epoch:  325\n",
      "Epoch: 0326, Training loss=0.10446059\n",
      "Epoch:  326\n",
      "Epoch: 0327, Training loss=0.10475498\n",
      "Epoch:  327\n",
      "Epoch: 0328, Training loss=0.10453536\n",
      "Epoch:  328\n",
      "Epoch: 0329, Training loss=0.10463551\n",
      "Epoch:  329\n",
      "Epoch: 0330, Training loss=0.10491422\n",
      "Epoch:  330\n",
      "Epoch: 0331, Training loss=0.10452749\n",
      "Epoch:  331\n",
      "Epoch: 0332, Training loss=0.10450014\n",
      "Epoch:  332\n",
      "Epoch: 0333, Training loss=0.10468751\n",
      "Epoch:  333\n",
      "Epoch: 0334, Training loss=0.10468850\n",
      "Epoch:  334\n",
      "Epoch: 0335, Training loss=0.10449699\n",
      "Epoch:  335\n",
      "Epoch: 0336, Training loss=0.10447093\n",
      "Epoch:  336\n",
      "Epoch: 0337, Training loss=0.10453050\n",
      "Epoch:  337\n",
      "Epoch: 0338, Training loss=0.10453328\n",
      "Epoch:  338\n",
      "Epoch: 0339, Training loss=0.10445282\n",
      "Epoch:  339\n",
      "Epoch: 0340, Training loss=0.10442247\n",
      "Epoch:  340\n",
      "Epoch: 0341, Training loss=0.10444029\n",
      "Epoch:  341\n",
      "Epoch: 0342, Training loss=0.10444953\n",
      "Epoch:  342\n",
      "Epoch: 0343, Training loss=0.10443081\n",
      "Epoch:  343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0344, Training loss=0.10441911\n",
      "Epoch:  344\n",
      "Epoch: 0345, Training loss=0.10443647\n",
      "Epoch:  345\n",
      "Epoch: 0346, Training loss=0.10443545\n",
      "Epoch:  346\n",
      "Epoch: 0347, Training loss=0.10441904\n",
      "Epoch:  347\n",
      "Epoch: 0348, Training loss=0.10443515\n",
      "Epoch:  348\n",
      "Epoch: 0349, Training loss=0.10443678\n",
      "Epoch:  349\n",
      "Epoch: 0350, Training loss=0.10441985\n",
      "Epoch:  350\n",
      "Epoch: 0351, Training loss=0.10445715\n",
      "Epoch:  351\n",
      "Epoch: 0352, Training loss=0.10443637\n",
      "Epoch:  352\n",
      "Epoch: 0353, Training loss=0.10445099\n",
      "Epoch:  353\n",
      "Epoch: 0354, Training loss=0.10453214\n",
      "Epoch:  354\n",
      "Epoch: 0355, Training loss=0.10442746\n",
      "Epoch:  355\n",
      "Epoch: 0356, Training loss=0.10468252\n",
      "Epoch:  356\n",
      "Epoch: 0357, Training loss=0.10459860\n",
      "Epoch:  357\n",
      "Epoch: 0358, Training loss=0.10451577\n",
      "Epoch:  358\n",
      "Epoch: 0359, Training loss=0.10484159\n",
      "Epoch:  359\n",
      "Epoch: 0360, Training loss=0.10456555\n",
      "Epoch:  360\n",
      "Epoch: 0361, Training loss=0.10447305\n",
      "Epoch:  361\n",
      "Epoch: 0362, Training loss=0.10459330\n",
      "Epoch:  362\n",
      "Epoch: 0363, Training loss=0.10462384\n",
      "Epoch:  363\n",
      "Epoch: 0364, Training loss=0.10449867\n",
      "Epoch:  364\n",
      "Epoch: 0365, Training loss=0.10451160\n",
      "Epoch:  365\n",
      "Epoch: 0366, Training loss=0.10462251\n",
      "Epoch:  366\n",
      "Epoch: 0367, Training loss=0.10458198\n",
      "Epoch:  367\n",
      "Epoch: 0368, Training loss=0.10447290\n",
      "Epoch:  368\n",
      "Epoch: 0369, Training loss=0.10443038\n",
      "Epoch:  369\n",
      "Epoch: 0370, Training loss=0.10446671\n",
      "Epoch:  370\n",
      "Epoch: 0371, Training loss=0.10448433\n",
      "Epoch:  371\n",
      "Epoch: 0372, Training loss=0.10443346\n",
      "Epoch:  372\n",
      "Epoch: 0373, Training loss=0.10443648\n",
      "Epoch:  373\n",
      "Epoch: 0374, Training loss=0.10446409\n",
      "Epoch:  374\n",
      "Epoch: 0375, Training loss=0.10443043\n",
      "Epoch:  375\n",
      "Epoch: 0376, Training loss=0.10442536\n",
      "Epoch:  376\n",
      "Epoch: 0377, Training loss=0.10445014\n",
      "Epoch:  377\n",
      "Epoch: 0378, Training loss=0.10442649\n",
      "Epoch:  378\n",
      "Epoch: 0379, Training loss=0.10443112\n",
      "Epoch:  379\n",
      "Epoch: 0380, Training loss=0.10445397\n",
      "Epoch:  380\n",
      "Epoch: 0381, Training loss=0.10442188\n",
      "Epoch:  381\n",
      "Epoch: 0382, Training loss=0.10446291\n",
      "Epoch:  382\n",
      "Epoch: 0383, Training loss=0.10446585\n",
      "Epoch:  383\n",
      "Epoch: 0384, Training loss=0.10443902\n",
      "Epoch:  384\n",
      "Epoch: 0385, Training loss=0.10456800\n",
      "Epoch:  385\n",
      "Epoch: 0386, Training loss=0.10443776\n",
      "Epoch:  386\n",
      "Epoch: 0387, Training loss=0.10460832\n",
      "Epoch:  387\n",
      "Epoch: 0388, Training loss=0.10461979\n",
      "Epoch:  388\n",
      "Epoch: 0389, Training loss=0.10445912\n",
      "Epoch:  389\n",
      "Epoch: 0390, Training loss=0.10478295\n",
      "Epoch:  390\n",
      "Epoch: 0391, Training loss=0.10456558\n",
      "Epoch:  391\n",
      "Epoch: 0392, Training loss=0.10447271\n",
      "Epoch:  392\n",
      "Epoch: 0393, Training loss=0.10458614\n",
      "Epoch:  393\n",
      "Epoch: 0394, Training loss=0.10453969\n",
      "Epoch:  394\n",
      "Epoch: 0395, Training loss=0.10444483\n",
      "Epoch:  395\n",
      "Epoch: 0396, Training loss=0.10444955\n",
      "Epoch:  396\n",
      "Epoch: 0397, Training loss=0.10448702\n",
      "Epoch:  397\n",
      "Epoch: 0398, Training loss=0.10448016\n",
      "Epoch:  398\n",
      "Epoch: 0399, Training loss=0.10443502\n",
      "Epoch:  399\n",
      "Epoch: 0400, Training loss=0.10444839\n",
      "Epoch:  400\n",
      "Epoch: 0401, Training loss=0.10447115\n",
      "Epoch:  401\n",
      "Epoch: 0402, Training loss=0.10443969\n",
      "Epoch:  402\n",
      "Epoch: 0403, Training loss=0.10443942\n",
      "Epoch:  403\n",
      "Epoch: 0404, Training loss=0.10446645\n",
      "Epoch:  404\n",
      "Epoch: 0405, Training loss=0.10443827\n",
      "Epoch:  405\n",
      "Epoch: 0406, Training loss=0.10442838\n",
      "Epoch:  406\n",
      "Epoch: 0407, Training loss=0.10446260\n",
      "Epoch:  407\n",
      "Epoch: 0408, Training loss=0.10442787\n",
      "Epoch:  408\n",
      "Epoch: 0409, Training loss=0.10444149\n",
      "Epoch:  409\n",
      "Epoch: 0410, Training loss=0.10446473\n",
      "Epoch:  410\n",
      "Epoch: 0411, Training loss=0.10442067\n",
      "Epoch:  411\n",
      "Epoch: 0412, Training loss=0.10448758\n",
      "Epoch:  412\n",
      "Epoch: 0413, Training loss=0.10445644\n",
      "Epoch:  413\n",
      "Epoch: 0414, Training loss=0.10446059\n",
      "Epoch:  414\n",
      "Epoch: 0415, Training loss=0.10457157\n",
      "Epoch:  415\n",
      "Epoch: 0416, Training loss=0.10442788\n",
      "Epoch:  416\n",
      "Epoch: 0417, Training loss=0.10461507\n",
      "Epoch:  417\n",
      "Epoch: 0418, Training loss=0.10454632\n",
      "Epoch:  418\n",
      "Epoch: 0419, Training loss=0.10446745\n",
      "Epoch:  419\n",
      "Epoch: 0420, Training loss=0.10463924\n",
      "Epoch:  420\n",
      "Epoch: 0421, Training loss=0.10448859\n",
      "Epoch:  421\n",
      "Epoch: 0422, Training loss=0.10445113\n",
      "Epoch:  422\n",
      "Epoch: 0423, Training loss=0.10452684\n",
      "Epoch:  423\n",
      "Epoch: 0424, Training loss=0.10447993\n",
      "Epoch:  424\n",
      "Epoch: 0425, Training loss=0.10442872\n",
      "Epoch:  425\n",
      "Epoch: 0426, Training loss=0.10446578\n",
      "Epoch:  426\n",
      "Epoch: 0427, Training loss=0.10447066\n",
      "Epoch:  427\n",
      "Epoch: 0428, Training loss=0.10442510\n",
      "Epoch:  428\n",
      "Epoch: 0429, Training loss=0.10444817\n",
      "Epoch:  429\n",
      "Epoch: 0430, Training loss=0.10446294\n",
      "Epoch:  430\n",
      "Epoch: 0431, Training loss=0.10442361\n",
      "Epoch:  431\n",
      "Epoch: 0432, Training loss=0.10444386\n",
      "Epoch:  432\n",
      "Epoch: 0433, Training loss=0.10446967\n",
      "Epoch:  433\n",
      "Epoch: 0434, Training loss=0.10442080\n",
      "Epoch:  434\n",
      "Epoch: 0435, Training loss=0.10447282\n",
      "Epoch:  435\n",
      "Epoch: 0436, Training loss=0.10447225\n",
      "Epoch:  436\n",
      "Epoch: 0437, Training loss=0.10443231\n",
      "Epoch:  437\n",
      "Epoch: 0438, Training loss=0.10455035\n",
      "Epoch:  438\n",
      "Epoch: 0439, Training loss=0.10444771\n",
      "Epoch:  439\n",
      "Epoch: 0440, Training loss=0.10454009\n",
      "Epoch:  440\n",
      "Epoch: 0441, Training loss=0.10461949\n",
      "Epoch:  441\n",
      "Epoch: 0442, Training loss=0.10443560\n",
      "Epoch:  442\n",
      "Epoch: 0443, Training loss=0.10463512\n",
      "Epoch:  443\n",
      "Epoch: 0444, Training loss=0.10459068\n",
      "Epoch:  444\n",
      "Epoch: 0445, Training loss=0.10444297\n",
      "Epoch:  445\n",
      "Epoch: 0446, Training loss=0.10452859\n",
      "Epoch:  446\n",
      "Epoch: 0447, Training loss=0.10456081\n",
      "Epoch:  447\n",
      "Epoch: 0448, Training loss=0.10447089\n",
      "Epoch:  448\n",
      "Epoch: 0449, Training loss=0.10444883\n",
      "Epoch:  449\n",
      "Epoch: 0450, Training loss=0.10448385\n",
      "Epoch:  450\n",
      "Epoch: 0451, Training loss=0.10449812\n",
      "Epoch:  451\n",
      "Epoch: 0452, Training loss=0.10444114\n",
      "Epoch:  452\n",
      "Epoch: 0453, Training loss=0.10444545\n",
      "Epoch:  453\n",
      "Epoch: 0454, Training loss=0.10447381\n",
      "Epoch:  454\n",
      "Epoch: 0455, Training loss=0.10444112\n",
      "Epoch:  455\n",
      "Epoch: 0456, Training loss=0.10442735\n",
      "Epoch:  456\n",
      "Epoch: 0457, Training loss=0.10444441\n",
      "Epoch:  457\n",
      "Epoch: 0458, Training loss=0.10444166\n",
      "Epoch:  458\n",
      "Epoch: 0459, Training loss=0.10442315\n",
      "Epoch:  459\n",
      "Epoch: 0460, Training loss=0.10444330\n",
      "Epoch:  460\n",
      "Epoch: 0461, Training loss=0.10443884\n",
      "Epoch:  461\n",
      "Epoch: 0462, Training loss=0.10442276\n",
      "Epoch:  462\n",
      "Epoch: 0463, Training loss=0.10445999\n",
      "Epoch:  463\n",
      "Epoch: 0464, Training loss=0.10442743\n",
      "Epoch:  464\n",
      "Epoch: 0465, Training loss=0.10445446\n",
      "Epoch:  465\n",
      "Epoch: 0466, Training loss=0.10448307\n",
      "Epoch:  466\n",
      "Epoch: 0467, Training loss=0.10442846\n",
      "Epoch:  467\n",
      "Epoch: 0468, Training loss=0.10457592\n",
      "Epoch:  468\n",
      "Epoch: 0469, Training loss=0.10445388\n",
      "Epoch:  469\n",
      "Epoch: 0470, Training loss=0.10456726\n",
      "Epoch:  470\n",
      "Epoch: 0471, Training loss=0.10464724\n",
      "Epoch:  471\n",
      "Epoch: 0472, Training loss=0.10443567\n",
      "Epoch:  472\n",
      "Epoch: 0473, Training loss=0.10460708\n",
      "Epoch:  473\n",
      "Epoch: 0474, Training loss=0.10464650\n",
      "Epoch:  474\n",
      "Epoch: 0475, Training loss=0.10447425\n",
      "Epoch:  475\n",
      "Epoch: 0476, Training loss=0.10450469\n",
      "Epoch:  476\n",
      "Epoch: 0477, Training loss=0.10457917\n",
      "Epoch:  477\n",
      "Epoch: 0478, Training loss=0.10451550\n",
      "Epoch:  478\n",
      "Epoch: 0479, Training loss=0.10446051\n",
      "Epoch:  479\n",
      "Epoch: 0480, Training loss=0.10448027\n",
      "Epoch:  480\n",
      "Epoch: 0481, Training loss=0.10453219\n",
      "Epoch:  481\n",
      "Epoch: 0482, Training loss=0.10449789\n",
      "Epoch:  482\n",
      "Epoch: 0483, Training loss=0.10445464\n",
      "Epoch:  483\n",
      "Epoch: 0484, Training loss=0.10445812\n",
      "Epoch:  484\n",
      "Epoch: 0485, Training loss=0.10450260\n",
      "Epoch:  485\n",
      "Epoch: 0486, Training loss=0.10447879\n",
      "Epoch:  486\n",
      "Epoch: 0487, Training loss=0.10442933\n",
      "Epoch:  487\n",
      "Epoch: 0488, Training loss=0.10445213\n",
      "Epoch:  488\n",
      "Epoch: 0489, Training loss=0.10446661\n",
      "Epoch:  489\n",
      "Epoch: 0490, Training loss=0.10443699\n",
      "Epoch:  490\n",
      "Epoch: 0491, Training loss=0.10442646\n",
      "Epoch:  491\n",
      "Epoch: 0492, Training loss=0.10444771\n",
      "Epoch:  492\n",
      "Epoch: 0493, Training loss=0.10444701\n",
      "Epoch:  493\n",
      "Epoch: 0494, Training loss=0.10442259\n",
      "Epoch:  494\n",
      "Epoch: 0495, Training loss=0.10443895\n",
      "Epoch:  495\n",
      "Epoch: 0496, Training loss=0.10445279\n",
      "Epoch:  496\n",
      "Epoch: 0497, Training loss=0.10442308\n",
      "Epoch:  497\n",
      "Epoch: 0498, Training loss=0.10444805\n",
      "Epoch:  498\n",
      "Epoch: 0499, Training loss=0.10445761\n",
      "Epoch:  499\n",
      "Epoch: 0500, Training loss=0.10442296\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for epoch in range(EPOCH):\n",
    "    print('Epoch: ',epoch)\n",
    "    for step,(batch_x,batch_y) in enumerate(trainDataLoader2):\n",
    "        b_x = Variable(batch_x)\n",
    "        b_y = Variable(batch_y)\n",
    "        # predict label\n",
    "        output = predictor(b_x)\n",
    "        # b_y=F.sigmoid(b_y) \n",
    "        \n",
    "        #print\n",
    "        #print(output)\n",
    "        #print(b_y)\n",
    "        # compute loss\n",
    "        loss = loss_func(output,b_y)\n",
    "        #loss = criterion(output, b_y)\n",
    "        \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_train[epoch,0] = loss.item()  \n",
    "    print('Epoch: %04d, Training loss=%.8f' %\n",
    "          (epoch+1, loss.item())) \n",
    "\n",
    "# Save model\n",
    "torch.save(predictor.state_dict(), 'saved/models/DNN_GDSC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tesing feature\n",
    "_,testFeature = autoencoder(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredict = predictor(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2343],\n",
       "        [0.2168],\n",
       "        [0.2243],\n",
       "        [0.2337],\n",
       "        [0.2166],\n",
       "        [0.2663],\n",
       "        [0.2910],\n",
       "        [0.2743],\n",
       "        [0.2034],\n",
       "        [0.2739],\n",
       "        [0.2607],\n",
       "        [0.2710],\n",
       "        [0.2828],\n",
       "        [0.2410],\n",
       "        [0.1940],\n",
       "        [0.2478],\n",
       "        [0.2325],\n",
       "        [0.2811],\n",
       "        [0.2589],\n",
       "        [0.2358],\n",
       "        [0.2513],\n",
       "        [0.2742],\n",
       "        [0.1638],\n",
       "        [0.2183],\n",
       "        [0.1812],\n",
       "        [0.2537],\n",
       "        [0.2488],\n",
       "        [0.2066],\n",
       "        [0.0644],\n",
       "        [0.2257],\n",
       "        [0.2081],\n",
       "        [0.1899],\n",
       "        [0.2967],\n",
       "        [0.2300],\n",
       "        [0.2832],\n",
       "        [0.2550],\n",
       "        [0.2008],\n",
       "        [0.2838],\n",
       "        [0.2039],\n",
       "        [0.2412],\n",
       "        [0.2903],\n",
       "        [0.2678],\n",
       "        [0.2008],\n",
       "        [0.2573],\n",
       "        [0.2536],\n",
       "        [0.2891],\n",
       "        [0.1939],\n",
       "        [0.2167],\n",
       "        [0.2740],\n",
       "        [0.2599],\n",
       "        [0.2401],\n",
       "        [0.2867],\n",
       "        [0.2378],\n",
       "        [0.2719],\n",
       "        [0.2295],\n",
       "        [0.2302],\n",
       "        [0.2724],\n",
       "        [0.3271],\n",
       "        [0.2488],\n",
       "        [0.1679],\n",
       "        [0.2829],\n",
       "        [0.2397],\n",
       "        [0.2884],\n",
       "        [0.2244],\n",
       "        [0.2686],\n",
       "        [0.2128],\n",
       "        [0.2629],\n",
       "        [0.2001],\n",
       "        [0.2524],\n",
       "        [0.2806],\n",
       "        [0.2291],\n",
       "        [0.2378],\n",
       "        [0.1957],\n",
       "        [0.2737],\n",
       "        [0.1921],\n",
       "        [0.2346],\n",
       "        [0.2315],\n",
       "        [0.2285],\n",
       "        [0.2532],\n",
       "        [0.2480],\n",
       "        [0.2057],\n",
       "        [0.2804],\n",
       "        [0.2434],\n",
       "        [0.2823],\n",
       "        [0.1608],\n",
       "        [0.1850],\n",
       "        [0.2034],\n",
       "        [0.2058],\n",
       "        [0.2413],\n",
       "        [0.2021],\n",
       "        [0.1557],\n",
       "        [0.2250],\n",
       "        [0.1817],\n",
       "        [0.2288],\n",
       "        [0.2436],\n",
       "        [0.2460],\n",
       "        [0.2652],\n",
       "        [0.2938],\n",
       "        [0.2873],\n",
       "        [0.2331],\n",
       "        [0.3721],\n",
       "        [0.3033],\n",
       "        [0.2209],\n",
       "        [0.2404],\n",
       "        [0.2949],\n",
       "        [0.1869],\n",
       "        [0.2765],\n",
       "        [0.2910],\n",
       "        [0.1959],\n",
       "        [0.2780],\n",
       "        [0.2443],\n",
       "        [0.2437],\n",
       "        [0.2341],\n",
       "        [0.1723],\n",
       "        [0.1994],\n",
       "        [0.2529],\n",
       "        [0.2806],\n",
       "        [0.3262],\n",
       "        [0.2714],\n",
       "        [0.2243],\n",
       "        [0.2016],\n",
       "        [0.2444],\n",
       "        [0.2617],\n",
       "        [0.2137],\n",
       "        [0.2414],\n",
       "        [0.2965],\n",
       "        [0.1997],\n",
       "        [0.2590],\n",
       "        [0.1816],\n",
       "        [0.2029],\n",
       "        [0.2199],\n",
       "        [0.1819],\n",
       "        [0.2488],\n",
       "        [0.2677],\n",
       "        [0.2359],\n",
       "        [0.2694],\n",
       "        [0.2636],\n",
       "        [0.2161],\n",
       "        [0.2350],\n",
       "        [0.1993],\n",
       "        [0.3193],\n",
       "        [0.2396],\n",
       "        [0.3236],\n",
       "        [0.2665],\n",
       "        [0.2465],\n",
       "        [0.2317],\n",
       "        [0.2619],\n",
       "        [0.2120],\n",
       "        [0.3203],\n",
       "        [0.2252],\n",
       "        [0.2379],\n",
       "        [0.2683],\n",
       "        [0.2700],\n",
       "        [0.2452],\n",
       "        [0.2530],\n",
       "        [0.2967],\n",
       "        [0.2459],\n",
       "        [0.1765]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-79.57991528596291"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(testpredict.detach().cpu().numpy(),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13058245534334187"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(testpredict.detach().cpu().numpy(),Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
